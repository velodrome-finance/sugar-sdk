{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# â›“ Chain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import asyncio, web3, os\n",
    "from dataclasses import dataclass\n",
    "from functools import wraps, reduce, partial\n",
    "import concurrent.futures\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import List, TypeVar, Callable, Optional, Tuple, Dict, Union\n",
    "from fastcore.utils import patch\n",
    "from web3 import Web3, HTTPProvider, AsyncWeb3, AsyncHTTPProvider, Account\n",
    "from web3.eth.async_eth import AsyncContract\n",
    "from web3.eth import Contract\n",
    "from web3.manager import RequestManager, RequestBatcher\n",
    "from sugar.config import ChainSettings, make_op_chain_settings, make_base_chain_settings\n",
    "from sugar.helpers import normalize_address, MAX_UINT256, float_to_uint256, apply_slippage, get_future_timestamp\n",
    "from sugar.abi import sugar, slipstream, price_oracle, router, quoter\n",
    "from sugar.token import Token\n",
    "from sugar.pool import LiquidityPool, LiquidityPoolForSwap\n",
    "from sugar.price import Price\n",
    "from sugar.deposit import Deposit\n",
    "from sugar.helpers import ADDRESS_ZERO, chunk, normalize_address, Pair, find_all_paths\n",
    "from sugar.quote import Quote, RouteInput, prepare_route\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monkey patching how web3 handles errors in batched requests\n",
    "# re: https://github.com/ethereum/web3.py/issues/3657\n",
    "original_format_batched_response = RequestManager._format_batched_response\n",
    "def safe_format_batched_response(*args):\n",
    "    try: return original_format_batched_response(*args)\n",
    "    except Exception as e: return e\n",
    "RequestManager._format_batched_response = safe_format_batched_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "T = TypeVar('T')\n",
    "\n",
    "def require_context(f: Callable[..., T]) -> Callable[..., T]:\n",
    "    @wraps(f)\n",
    "    def wrapper(self: 'CommonChain', *args, **kwargs) -> T:\n",
    "        if not self._in_context: raise RuntimeError(\"Chain methods can only be accessed within 'async with' block\")\n",
    "        return f(self, *args, **kwargs)\n",
    "    return wrapper\n",
    "\n",
    "def require_async_context(f: Callable[..., T]) -> Callable[..., T]:\n",
    "    @wraps(f)\n",
    "    async def wrapper(self: 'CommonChain', *args, **kwargs) -> T:\n",
    "        if not self._in_context: raise RuntimeError(\"Chain methods can only be accessed within 'async with' block\")\n",
    "        return await f(self, *args, **kwargs)\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "class CommonChain:\n",
    "    @property\n",
    "    def account(self) -> Account: return self.web3.eth.account.from_key(os.getenv(\"SUGAR_PK\"))\n",
    "\n",
    "    def __init__(self, settings: ChainSettings):\n",
    "        self.settings, self._in_context = settings, False\n",
    "    \n",
    "    def prepare_tokens(self, tokens: List[Tuple], listed_only: bool) -> List[Token]:\n",
    "        native = Token.make_native_token(self.settings.native_token_symbol, self.settings.wrapped_native_token_addr, self.settings.native_token_decimals)\n",
    "        ts = list(map(lambda t: Token.from_tuple(t), tokens))\n",
    "        return [native] + (list(filter(lambda t: t.listed, ts)) if listed_only else ts)\n",
    "    \n",
    "    def _prepare_prices(self, tokens: List[Token], rates: List[int]) -> Dict[str, int]:\n",
    "        # token_address => normalized rate\n",
    "        result = {}\n",
    "        # rates are returned multiplied by eth decimals + the difference in decimals to eth\n",
    "        # we want them all normalized to 18 decimals\n",
    "        for cnt, rate in enumerate(rates):\n",
    "            t, eth_decimals = tokens[cnt], self.settings.native_token_decimals\n",
    "            if t.decimals == eth_decimals: nr = rate\n",
    "            elif t.decimals < eth_decimals: nr = rate // (10 ** (eth_decimals - t.decimals))\n",
    "            else: nr = rate * (10 ** (t.decimals - eth_decimals))\n",
    "            result[t.token_address] = nr\n",
    "        return result\n",
    "\n",
    "    def prepare_prices(self, tokens: List[Token], prices: List[int]) -> List[Price]:\n",
    "        \"\"\"Get prices for tokens in target stable token\"\"\"\n",
    "        eth_decimals = self.settings.native_token_decimals\n",
    "        # all rates in EHT: token => rate\n",
    "        rates_in_eth = self._prepare_prices(tokens, prices)\n",
    "        eth_rate, usd_rate = rates_in_eth[self.settings.native_token_symbol], rates_in_eth[self.settings.stable_token_addr]\n",
    "        # this gives us the price of 1 eth in usd with 18 decimals precision\n",
    "        eth_usd_price = (eth_rate * 10 ** eth_decimals) // usd_rate\n",
    "        # finally convert to prices in terms of stable\n",
    "        return [Price(token=t, price=(rates_in_eth[t.token_address] * eth_usd_price // 10 ** eth_decimals) / 10 ** eth_decimals) for t in tokens]\n",
    "    \n",
    "    def prepare_pools(self, pools: List[Tuple], tokens: List[Token], prices: List[Price]) -> List[LiquidityPool]:\n",
    "        tokens, prices = {t.token_address: t for t in tokens}, {price.token.token_address: price for price in prices}\n",
    "        return list(filter(lambda p: p is not None, map(lambda p: LiquidityPool.from_tuple(p, tokens, prices), pools)))\n",
    "    \n",
    "    def prepare_pools_for_swap(self, pools: List[Tuple], tokens: List[Token]) -> List[LiquidityPoolForSwap]:\n",
    "        tokens = {t.token_address: t for t in tokens}\n",
    "        return list(filter(lambda p: p is not None, map(lambda p: LiquidityPoolForSwap.from_tuple(p, tokens), pools)))\n",
    "    \n",
    "    def prepare_quote_batch(self, batcher: RequestBatcher, pools: List[List[LiquidityPoolForSwap]], amount_in: int, paths: List[List[Tuple]]):\n",
    "        for i, path in enumerate(paths):\n",
    "            #print(f\">>>>>>>>>> processing pools: {pools}\")\n",
    "            rt = prepare_route([RouteInput(pool=p, reversed=p.token0.token_address != path[i][0]) for i, p in enumerate(pools[i])])\n",
    "            #print(f\">>>>>>>>>> calling quoteExactInput with {amount_in} {rt.encoded}\")\n",
    "            batcher.add(self.quoter.functions.quoteExactInput(rt.encoded, amount_in))\n",
    "        return batcher\n",
    "\n",
    "    def prepare_quotes(self, from_token:Token, to_token:Token, amount_in: int, path_pools: List[List[LiquidityPoolForSwap]], responses):\n",
    "        quotes = []\n",
    "        for i, r in enumerate(responses):\n",
    "            if isinstance(r, Exception): continue\n",
    "            else: quotes.append(Quote(from_token=from_token, to_token=to_token, path=path_pools[i], amount_in=amount_in, amount_out=r[0]))\n",
    "        return quotes\n",
    "    \n",
    "    def get_paths_for_quote(self, from_token: Token, to_token: Token, pools: List[LiquidityPoolForSwap], exclude_tokens: List[str]) -> List[List[Tuple]]:\n",
    "        exclude_tokens_set = set(map(lambda t: normalize_address(t), exclude_tokens))\n",
    "\n",
    "        if from_token.token_address in exclude_tokens: exclude_tokens_set.remove(from_token.token_address)\n",
    "        if to_token.token_address in exclude_tokens: exclude_tokens_set.remove(to_token.token_address)\n",
    "\n",
    "        pairs = [Pair(p.token0.token_address, p.token1.token_address, p.lp) for p in pools]\n",
    "        paths = find_all_paths(pairs, from_token.wrapped_token_address or from_token.token_address, to_token.wrapped_token_address or to_token.token_address)\n",
    "        # filter out paths with excluded tokens\n",
    "        return list(filter(lambda p: len(set(map(lambda t: t[0], p)) & exclude_tokens_set) == 0, paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aync chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class AsyncChain(CommonChain):\n",
    "    web3: AsyncWeb3\n",
    "    sugar: AsyncContract\n",
    "    slipstream: AsyncContract\n",
    "    router: AsyncContract\n",
    "    prices: AsyncContract\n",
    "    quoter: AsyncContract\n",
    "\n",
    "\n",
    "    async def __aenter__(self):\n",
    "        \"\"\"Async context manager entry\"\"\"\n",
    "        self._in_context = True\n",
    "        self.web3 = AsyncWeb3(AsyncHTTPProvider(self.settings.rpc_uri))\n",
    "        self.sugar = self.web3.eth.contract(address=self.settings.sugar_contract_addr, abi=sugar)\n",
    "        self.slipstream = self.web3.eth.contract(address=self.settings.slipstream_contract_addr, abi=slipstream)\n",
    "        self.prices = self.web3.eth.contract(address=self.settings.price_oracle_contract_addr, abi=price_oracle)\n",
    "        self.router = self.web3.eth.contract(address=self.settings.router_contract_addr, abi=router)\n",
    "        self.quoter = self.web3.eth.contract(address=self.settings.quoter_contract_addr, abi=quoter)\n",
    "        return self\n",
    "\n",
    "    async def __aexit__(self, exc_type, exc_val, exc_tb):\n",
    "        \"\"\"Async context manager exit\"\"\"\n",
    "        self._in_context = False\n",
    "        await self.web3.provider.disconnect()\n",
    "        return None\n",
    "\n",
    "    @require_async_context\n",
    "    async def get_all_tokens(self, listed_only: bool = True) -> List[Token]:\n",
    "        # TODO: pagination for tokens\n",
    "        tokens = await self.sugar.functions.tokens(1000, 0, ADDRESS_ZERO, []).call()\n",
    "        return self.prepare_tokens(tokens, listed_only)\n",
    "    \n",
    "    # @cache_in_seconds(ORACLE_PRICES_CACHE_MINUTES * 60)\n",
    "    async def _get_prices(self, tokens: Tuple[Token]) -> List[int]:\n",
    "        # token_address => normalized rate\n",
    "        return await self.prices.functions.getManyRatesToEthWithCustomConnectors(\n",
    "            list(map(lambda t: t.wrapped_token_address or t.token_address, tokens)),\n",
    "            False, # use wrappers\n",
    "            self.settings.connector_tokens_addrs,\n",
    "            10 # threshold_filter\n",
    "        ).call()\n",
    "\n",
    "    @require_async_context\n",
    "    async def get_prices(self, tokens: List[Token]) -> List[Price]:\n",
    "        \"\"\"Get prices for tokens in target stable token\"\"\"\n",
    "\n",
    "        # batches starts as a list of lists \n",
    "        batches = await asyncio.gather(\n",
    "            *map(\n",
    "                # XX: lists are not cacheable, convert them to tuples so lru cache is happy\n",
    "                lambda ts: self._get_prices(tuple(ts)),\n",
    "                list(chunk(tokens, self.settings.price_batch_size)),\n",
    "            )\n",
    "        )\n",
    "        return self.prepare_prices(tokens, sum(batches, []))\n",
    "\n",
    "    @require_async_context\n",
    "    async def get_pools(self, for_swaps: bool = False) -> List[LiquidityPool]:\n",
    "        pools, offset, limit = [], 0, self.settings.pool_page_size\n",
    "        tokens = await self.get_all_tokens()\n",
    "        \n",
    "        while True:\n",
    "            f = self.sugar.functions.all if not for_swaps else self.sugar.functions.forSwaps\n",
    "            pools_batch = await f(limit, offset).call()\n",
    "            pools += pools_batch\n",
    "            if len(pools_batch) < limit: break\n",
    "            else: offset += limit\n",
    "\n",
    "        return self.prepare_pools(pools, tokens, await self.get_prices(tokens)) if not for_swaps else self.prepare_pools_for_swap(pools, tokens)\n",
    "    \n",
    "    \n",
    "    @require_async_context\n",
    "    async def get_pools_for_swaps(self) -> List[LiquidityPoolForSwap]: return await self.get_pools(for_swaps=True)\n",
    "\n",
    "    @require_async_context\n",
    "    async def _get_quotes_for_paths(self, from_token: Token, to_token: Token, amount_in: int, pools: List[LiquidityPoolForSwap], paths: List[List[Tuple]]) -> List[Optional[Quote]]:\n",
    "        pools_dict = {p.lp: p for p in pools}\n",
    "        path_pools = [list(map(lambda p: pools_dict[p[2]], path)) for path in paths]\n",
    "        async with self.web3.batch_requests() as batch:\n",
    "            batch = self.prepare_quote_batch(batch, path_pools, amount_in, paths)\n",
    "            return self.prepare_quotes(from_token, to_token, amount_in, path_pools, await batch.async_execute())\n",
    "\n",
    "    @require_async_context\n",
    "    async def get_quote(self, from_token: Token, to_token: Token, amount_in: int, exclude_tokens: List[str] = []) -> Optional[Quote]:\n",
    "        pools = await self.get_pools_for_swaps()\n",
    "        paths = self.get_paths_for_quote(from_token, to_token, pools, exclude_tokens)\n",
    "        quotes = sum(await asyncio.gather(*[self._get_quotes_for_paths(from_token, to_token, amount_in, pools, paths) for paths in chunk(paths, 500)]), [])\n",
    "        return max(quotes, key=lambda q: q.amount_out) if len(quotes) > 0 else None\n",
    "\n",
    "    @require_async_context\n",
    "    async def set_token_allowance(self, token: Token, addr: str, amount: int):\n",
    "        ERC20_ABI = [{\n",
    "            \"name\": \"approve\",\n",
    "            \"type\": \"function\",\n",
    "            \"constant\": False,\n",
    "            \"inputs\": [{\"name\": \"spender\", \"type\": \"address\"}, {\"name\": \"amount\", \"type\": \"uint256\"}],\n",
    "            \"outputs\": [{\"name\": \"\", \"type\": \"bool\"}]\n",
    "        }]\n",
    "        token_contract = self.web3.eth.contract(address=token.token_address, abi=ERC20_ABI)\n",
    "        return await self.sign_and_send_tx(token_contract.functions.approve(addr, amount))\n",
    "\n",
    "    @require_async_context\n",
    "    async def check_token_allowance(self, token: Token, addr: str) -> int:\n",
    "        ERC20_ABI = [{\n",
    "            \"name\": \"allowance\",\n",
    "            \"type\": \"function\",\n",
    "            \"constant\": True,\n",
    "            \"inputs\": [{\"name\": \"owner\", \"type\": \"address\"}, {\"name\": \"spender\", \"type\": \"address\"}],\n",
    "            \"outputs\": [{\"name\": \"\", \"type\": \"uint256\"}]\n",
    "        }]\n",
    "        token_contract = self.web3.eth.contract(address=token.token_address, abi=ERC20_ABI)\n",
    "        return await token_contract.functions.allowance(self.account.address, addr).call()\n",
    "\n",
    "    @require_async_context\n",
    "    async def sign_and_send_tx(self, tx, value: int = 0, wait: bool = True):\n",
    "        print(f\"sign_and_send_tx: {tx} with value: {value}\")\n",
    "        spender = self.account.address\n",
    "        tx = await tx.build_transaction({ 'from': spender, 'value': value, 'nonce': await self.web3.eth.get_transaction_count(spender) })\n",
    "        signed_tx = self.account.sign_transaction(tx)\n",
    "        tx_hash = await self.web3.eth.send_raw_transaction(signed_tx.raw_transaction)\n",
    "        return await self.web3.eth.wait_for_transaction_receipt(tx_hash) if wait else tx_hash\n",
    "    \n",
    "    @require_async_context\n",
    "    async def deposit(self, deposit: Deposit, delay_in_minutes: float = 30, slippage: float = 0.01):\n",
    "        amount_token0, pool, router_contract_addr = deposit.amount_token0, deposit.pool, self.settings.router_contract_addr\n",
    "        print(f\"gonna deposit {amount_token0} {pool.token0.symbol} into {pool.symbol} from {self.account.address}\")\n",
    "        [token0_amount, token1_amount, _] = await self.router.functions.quoteAddLiquidity(\n",
    "            pool.token0.token_address,\n",
    "            pool.token1.token_address,\n",
    "            pool.is_stable,\n",
    "            pool.factory,\n",
    "            float_to_uint256(amount_token0, pool.token0.decimals),\n",
    "            MAX_UINT256\n",
    "        ).call()\n",
    "        print(f\"Quote: {pool.token0.symbol} {token0_amount / 10 ** pool.token0.decimals} -> {pool.token1.symbol} {token1_amount / 10 ** pool.token1.decimals}\")\n",
    "\n",
    "        # set up allowance for both tokens\n",
    "        print(f\"setting up allowance for {pool.token0.symbol}\")\n",
    "        await self.set_token_allowance(pool.token0, router_contract_addr, token0_amount)\n",
    "\n",
    "        print(f\"setting up allowance for {pool.token1.symbol}\")\n",
    "        await self.set_token_allowance(pool.token1, router_contract_addr, token1_amount)\n",
    "\n",
    "        # check allowances\n",
    "        token0_allowance = await self.check_token_allowance(pool.token0, router_contract_addr)\n",
    "        token1_allowance = await self.check_token_allowance(pool.token1, router_contract_addr)\n",
    "\n",
    "        print(f\"allowances: {token0_allowance}, {token1_allowance}\")\n",
    "\n",
    "        # adding liquidity\n",
    "\n",
    "        # if token 0 is native, use addLiquidityETH instead of standard addLiquidity\n",
    "        if pool.token0.token_address == self.settings.wrapped_native_token_addr:\n",
    "            params = [\n",
    "                pool.token1.token_address,\n",
    "                pool.is_stable,\n",
    "                token1_amount,\n",
    "                apply_slippage(token1_amount, slippage),\n",
    "                apply_slippage(token0_amount, slippage),\n",
    "                self.account.address,\n",
    "                get_future_timestamp(delay_in_minutes)\n",
    "            ]\n",
    "            print(f\"adding liquidity with params: {params}\")\n",
    "            return await self.sign_and_send_tx(self.router.functions.addLiquidityETH(*params), value=token0_amount)\n",
    "        \n",
    "        # token 1 is native, use addLiquidityETH instead of standard addLiquidity\n",
    "        if pool.token1.token_address == self.settings.wrapped_native_token_addr:\n",
    "            params = [\n",
    "                pool.token0.token_address,\n",
    "                pool.is_stable,\n",
    "                token0_amount,\n",
    "                apply_slippage(token0_amount, slippage),\n",
    "                apply_slippage(token1_amount, slippage),\n",
    "                self.account.address,\n",
    "                get_future_timestamp(delay_in_minutes)\n",
    "            ]\n",
    "            print(f\"adding liquidity with params: {params}\")\n",
    "            return await self.sign_and_send_tx(self.router.functions.addLiquidityETH(*params), value=token1_amount)\n",
    "\n",
    "        params = [\n",
    "            pool.token0.token_address,\n",
    "            pool.token1.token_address,\n",
    "            pool.is_stable,\n",
    "            token0_amount,\n",
    "            token1_amount,\n",
    "            apply_slippage(token0_amount, slippage),\n",
    "            apply_slippage(token1_amount, slippage),\n",
    "            self.account.address,\n",
    "            get_future_timestamp(delay_in_minutes)\n",
    "        ]\n",
    "\n",
    "        print(f\"adding liquidity with params: {params}\")\n",
    "\n",
    "        return await self.sign_and_send_tx(self.router.functions.addLiquidity(*params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sync chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class Chain(CommonChain):\n",
    "    web3: Web3\n",
    "    sugar: Contract\n",
    "    router: Contract\n",
    "    slipstream: Contract\n",
    "    prices: Contract\n",
    "    quoter: Contract\n",
    "\n",
    "    def __enter__(self):\n",
    "        \"\"\"Sync context manager entry\"\"\"\n",
    "        self._in_context = True\n",
    "        self.web3 = Web3(HTTPProvider(self.settings.rpc_uri))\n",
    "        self.sugar = self.web3.eth.contract(address=self.settings.sugar_contract_addr, abi=sugar)\n",
    "        self.slipstream = self.web3.eth.contract(address=self.settings.slipstream_contract_addr, abi=slipstream)\n",
    "        self.prices = self.web3.eth.contract(address=self.settings.price_oracle_contract_addr, abi=price_oracle)\n",
    "        self.router = self.web3.eth.contract(address=self.settings.router_contract_addr, abi=router)\n",
    "        self.quoter = self.web3.eth.contract(address=self.settings.quoter_contract_addr, abi=quoter)\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        \"\"\"Sync context manager exit\"\"\"\n",
    "        self._in_context = False\n",
    "        return None\n",
    "    \n",
    "    @require_context\n",
    "    def get_all_tokens(self, listed_only: bool = True) -> List[Token]:\n",
    "        return self.prepare_tokens(self.sugar.functions.tokens(800, 0, ADDRESS_ZERO, []).call(), listed_only)\n",
    "    \n",
    "    # @cache_in_seconds(ORACLE_PRICES_CACHE_MINUTES * 60)\n",
    "    def _get_prices(self, tokens: Tuple[Token]) -> List[int]:\n",
    "        # token_address => normalized rate\n",
    "        return self.prices.functions.getManyRatesToEthWithCustomConnectors(\n",
    "            list(map(lambda t: t.wrapped_token_address or t.token_address, tokens)),\n",
    "            False, # use wrappers\n",
    "            self.settings.connector_tokens_addrs,\n",
    "            10 # threshold_filter\n",
    "        ).call()\n",
    "\n",
    "    @require_context\n",
    "    def get_prices(self, tokens: List[Token]) -> List[Price]:\n",
    "        \"\"\"Get prices for tokens in target stable token\"\"\"\n",
    "        return self.prepare_prices(tokens, sum([self._get_prices(tuple(ts)) for ts in list(chunk(tokens, self.settings.price_batch_size))], []))\n",
    "    \n",
    "    @require_context\n",
    "    def get_pools(self, for_swaps: bool = False) -> List[LiquidityPool]:\n",
    "        pools, offset, limit = [], 0, self.settings.pool_page_size\n",
    "        tokens = self.get_all_tokens(listed_only=False)\n",
    "\n",
    "        while True:\n",
    "            f = self.sugar.functions.all if not for_swaps else self.sugar.functions.forSwaps\n",
    "            pools_batch = f(limit, offset).call()\n",
    "            pools += pools_batch\n",
    "            if len(pools_batch) == 0: break\n",
    "            else: offset += limit\n",
    "\n",
    "        return self.prepare_pools(pools, tokens, self.get_prices(tokens)) if not for_swaps else self.prepare_pools_for_swap(pools, tokens)\n",
    "    \n",
    "    @require_context\n",
    "    def get_pools_for_swaps(self) -> List[LiquidityPoolForSwap]: return self.get_pools(for_swaps=True)\n",
    "\n",
    "    @require_context\n",
    "    def _get_quotes_for_paths(self, from_token: Token, to_token: Token, amount_in: int, pools: List[LiquidityPoolForSwap], paths: List[List[Tuple]]) -> List[Optional[Quote]]:\n",
    "        pools_dict = {p.lp: p for p in pools}\n",
    "        path_pools = [list(map(lambda p: pools_dict[p[2]], path)) for path in paths]\n",
    "        with self.web3.batch_requests() as batch:\n",
    "            batch = self.prepare_quote_batch(batch, path_pools, amount_in, paths)\n",
    "            return self.prepare_quotes(from_token, to_token, amount_in, path_pools, batch.execute())\n",
    "\n",
    "    @require_context\n",
    "    def get_quote(self, from_token: Token, to_token: Token, amount_in: int, exclude_tokens: List[str] = []) -> Optional[Quote]:\n",
    "        pools = self.get_pools_for_swaps()\n",
    "        paths = self.get_paths_for_quote(from_token, to_token, pools, exclude_tokens)\n",
    "        path_chunks = list(chunk(paths, 500))\n",
    "        \n",
    "        # Store self reference for thread context\n",
    "        chain_instance = self\n",
    "        \n",
    "        def get_quotes_for_chunk(paths_chunk):\n",
    "            \"\"\"Thread-safe function to get quotes for a chunk of paths\"\"\"\n",
    "            return chain_instance._get_quotes_for_paths(from_token, to_token, amount_in, pools, paths_chunk)\n",
    "        \n",
    "        # Collect all quotes from all threads\n",
    "        all_quotes = []\n",
    "        # with ThreadPoolExecutor() as executor:\n",
    "        #     futures = [executor.submit(get_quotes_for_chunk, pc) for pc in path_chunks]\n",
    "        #     for future in concurrent.futures.as_completed(futures):\n",
    "        #         try:\n",
    "        #             quotes_batch = future.result()\n",
    "        #             all_quotes.extend(quotes_batch)\n",
    "        #         except Exception as e:\n",
    "        #             print(f\"Error getting quotes: {e}\")\n",
    "        \n",
    "        # # Return best quote\n",
    "        # return max(all_quotes, key=lambda q: q.amount_out) if len(all_quotes) > 0 else None\n",
    "\n",
    "        for pc in path_chunks:\n",
    "            quotes = get_quotes_for_chunk(pc)\n",
    "            for q in quotes: all_quotes.append(q)\n",
    "            # print(f\">>>>>>> {}\")\n",
    "\n",
    "        return max(all_quotes, key=lambda q: q.amount_out) if len(all_quotes) > 0 else None\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OP Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class OPChainCommon():\n",
    "    usdc: str = normalize_address(\"0x0b2C639c533813f4Aa9D7837CAf62653d097Ff85\")\n",
    "    velo: str = normalize_address(\"0x9560e827aF36c94D2Ac33a39bCE1Fe78631088Db\")\n",
    "\n",
    "class AsyncOPChain(AsyncChain, OPChainCommon):\n",
    "    def __init__(self, **kwargs): super().__init__(make_op_chain_settings(**kwargs))\n",
    "\n",
    "class OPChain(Chain, OPChainCommon):\n",
    "    def __init__(self, **kwargs): super().__init__(make_op_chain_settings(**kwargs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000000000000000000 -> 3.783388\n",
      "CL50-VELO/opxVELO - CL200-USDC/opxVELO\n"
     ]
    }
   ],
   "source": [
    "with OPChain() as op:\n",
    "    tokens = op.get_all_tokens(listed_only=True)\n",
    "    def get_token_by_addres(addr): return next(filter(lambda t: t.token_address == addr, tokens), None)\n",
    "    from_token_addr, to_token_addr = normalize_address(\"0x9560e827af36c94d2ac33a39bce1fe78631088db\"), normalize_address(\"0x0b2c639c533813f4aa9d7837caf62653d097ff85\") \n",
    "    from_token, to_token, amount_in = get_token_by_addres(from_token_addr), get_token_by_addres(to_token_addr), float_to_uint256(100)\n",
    "    exclude_tokens = [\"0x74ccbe53f77b08632ce0cb91d3a545bf6b8e0979\", \"0x139283255069ea5deef6170699aaef7139526f1f\", \"0x88a89866439f4c2830986b79cbe6f69d1bd548bb\", \"0x8901cb2e82cc95c01e42206f8d1f417fe53e7af0\"]\n",
    "    q = op.get_quote(from_token, to_token, amount_in, exclude_tokens)\n",
    "    if q:\n",
    "        print(f\"{q.amount_in} -> {q.amount_out / 10 ** to_token.decimals}\")\n",
    "        print(' - '.join(map(lambda p: p.symbol, q.path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class BaseChainCommon():\n",
    "    usdc: str = normalize_address(\"0x833589fcd6edb6e08f4c7c32d4f71b54bda02913\")\n",
    "    aero: str = normalize_address(\"0x940181a94a35a4569e4529a3cdfb74e38fd98631\")\n",
    "\n",
    "class AsyncBaseChain(AsyncChain, BaseChainCommon):\n",
    "    def __init__(self, **kwargs): super().__init__(make_base_chain_settings(**kwargs))\n",
    "\n",
    "class BaseChain(Chain, BaseChainCommon):\n",
    "    def __init__(self, **kwargs): super().__init__(make_base_chain_settings(**kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simnet versions of chains\n",
    "\n",
    "Simnet URIs:\n",
    "\n",
    "- OP: http://127.0.0.1:4444\n",
    "- Base: http://127.0.0.1:4445\n",
    "\n",
    "This assumes the following setup:\n",
    "\n",
    "```\n",
    "supersim fork  --l2.host=0.0.0.0 --l2.starting.port=4444 --chains=op,base\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "class AsyncOPChainSimnet(AsyncOPChain):\n",
    "    def __init__(self,  **kwargs): super().__init__(rpc_uri=\"http://127.0.0.1:4444\", **kwargs)\n",
    "\n",
    "class AsyncBaseChainSimnet(AsyncBaseChain):\n",
    "    def __init__(self,  **kwargs): super().__init__(rpc_uri=\"http://127.0.0.1:4445\", **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "Run tests using mainnets for reads and simnet for writes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure simnet is running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "==:\n61\n0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m     sock\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      8\u001b[0m     result \u001b[38;5;241m=\u001b[39m sock\u001b[38;5;241m.\u001b[39mconnect_ex((host, port))\n\u001b[0;32m----> 9\u001b[0m     \u001b[43mtest_eq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39merror \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m     11\u001b[0m     test_eq(err, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/projects/sugar-sdk/env/lib/python3.10/site-packages/fastcore/test.py:39\u001b[0m, in \u001b[0;36mtest_eq\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtest_eq\u001b[39m(a,b):\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`test` that `a==b`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 39\u001b[0m     \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43mequals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m==\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/sugar-sdk/env/lib/python3.10/site-packages/fastcore/test.py:29\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(a, b, cmp, cname)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`assert` that `cmp(a,b)`; display inputs and `cname or cmp.__name__` if it fails\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cname \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: cname\u001b[38;5;241m=\u001b[39mcmp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m cmp(a,b),\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00ma\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mb\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: ==:\n61\n0"
     ]
    }
   ],
   "source": [
    "from fastcore.test import test_eq\n",
    "import socket\n",
    "\n",
    "host, port ='127.0.0.1', 4444\n",
    "try:\n",
    "    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    sock.settimeout(2)\n",
    "    result = sock.connect_ex((host, port))\n",
    "    test_eq(result, 0)\n",
    "except socket.error as err:\n",
    "    test_eq(err, None)\n",
    "finally:\n",
    "    sock.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure PK is set for writes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from fastcore.test import test_ne\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "test_ne(os.getenv(\"SUGAR_PK\"), None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting tokens. Make sure native token is included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import test_eq, test_ne\n",
    "\n",
    "async with AsyncOPChain() as op:\n",
    "    tokens = await op.get_all_tokens()\n",
    "    native_token = next(filter(lambda t: t.is_native, tokens), None)\n",
    "    test_ne(native_token, None)\n",
    "    test_eq(native_token.symbol, \"ETH\")\n",
    "\n",
    "with OPChain() as op_sync:\n",
    "    tokens = op_sync.get_all_tokens()\n",
    "    native_token = next(filter(lambda t: t.is_native, tokens), None)\n",
    "    test_ne(native_token, None)\n",
    "    test_eq(native_token.symbol, \"ETH\")\n",
    "\n",
    "async with AsyncBaseChain() as base:\n",
    "    tokens = await base.get_all_tokens()\n",
    "    native_token = next(filter(lambda t: t.is_native, tokens), None)\n",
    "    test_ne(native_token, None)\n",
    "    test_eq(native_token.symbol, \"ETH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check on tokens and pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async with AsyncOPChain() as chain:\n",
    "    tokens = await chain.get_all_tokens()\n",
    "    prices = await chain.get_prices(tokens)\n",
    "    pools = await chain.get_pools()\n",
    "\n",
    "    for p in prices[:5]: print(f\"{p.token.symbol} price: ${p.price}\")\n",
    "    for p in pools[:5]: print(f\"{p.symbol} pool: ${p.tvl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000000000000000000 -> 3.751304\n",
      "vAMM-USDC/VELO\n"
     ]
    }
   ],
   "source": [
    "async with AsyncOPChain() as op:\n",
    "    tokens = await op.get_all_tokens(listed_only=True)\n",
    "    def get_token_by_addres(addr): return next(filter(lambda t: t.token_address == addr, tokens), None)\n",
    "    from_token_addr, to_token_addr = normalize_address(\"0x9560e827af36c94d2ac33a39bce1fe78631088db\"), normalize_address(\"0x0b2c639c533813f4aa9d7837caf62653d097ff85\") \n",
    "    from_token, to_token, amount_in = get_token_by_addres(from_token_addr), get_token_by_addres(to_token_addr), float_to_uint256(100)\n",
    "    exclude_tokens = [\"0x74ccbe53f77b08632ce0cb91d3a545bf6b8e0979\", \"0x139283255069ea5deef6170699aaef7139526f1f\", \"0x88a89866439f4c2830986b79cbe6f69d1bd548bb\", \"0x8901cb2e82cc95c01e42206f8d1f417fe53e7af0\"]\n",
    "    q = await op.get_quote(from_token, to_token, amount_in, exclude_tokens)\n",
    "    if q:\n",
    "        print(f\"{q.amount_in} -> {q.amount_out / 10 ** to_token.decimals}\")\n",
    "        print(' - '.join(map(lambda p: p.symbol, q.path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with OPChain() as chain:\n",
    "    tokens = chain.get_all_tokens()\n",
    "    prices = chain.get_prices(tokens)\n",
    "    pools = chain.get_pools()\n",
    "\n",
    "    for p in prices[:5]: print(f\"{p.token.symbol} price: ${p.price}\")\n",
    "    for p in pools[:5]: print(f\"{p.symbol} pool: ${p.tvl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic deposit on OP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async with AsyncOPChain() as chain:\n",
    "    pools = await chain.get_pools()\n",
    "    pools = list(filter(lambda x: x.token0 and x.token0.token_address == chain.usdc and x.token1.token_address == chain.velo, pools))\n",
    "    async with AsyncOPChainSimnet() as supersim:\n",
    "        print(f\"supersim is {supersim}\")\n",
    "        # 0.02 USDC \n",
    "        await supersim.deposit(Deposit(pools[0], 0.02))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Native -> non Native on OP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WIP\n",
    "# async with OPChain() as op:\n",
    "#     pools = await op.get_pools()\n",
    "#     # find WETH/Velo pool\n",
    "#     weth_velo_pool = next(filter(lambda p: p.token0.token_address == op.settings.wrapped_native_token_addr and p.token1.token_address == OPChain.velo, pools), None)\n",
    "#     test_ne(weth_velo_pool, None)\n",
    "#     async with OPChainSimnet() as supersim:\n",
    "#         await supersim.deposit(Deposit(weth_velo_pool, 0.0001))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic deposit on Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async with AsyncBaseChain() as chain:\n",
    "    pools = await chain.get_pools()\n",
    "    pools = list(filter(lambda x: x.token0 and x.token0.token_address == chain.usdc and x.token1.token_address == chain.aero, pools))\n",
    "    async with AsyncBaseChainSimnet() as supersim:\n",
    "        # 0.02 USDC \n",
    "        await supersim.deposit(Deposit(pools[0], 0.01), slippage=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CL on OP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIP\n",
    "# async with OPChain() as chain:\n",
    "#     pools = await chain.get_pools()\n",
    "#     # CL200-USDC/VELO\n",
    "#     cl_usdc_velo = next(filter(lambda x: x.token0 and x.token0.token_address == chain.usdc and x.token1.token_address == chain.velo and x.is_cl, pools), None)\n",
    "#     test_ne(cl_usdc_velo, None)\n",
    "#     async with OPChainSimnet() as supersim:\n",
    "#         await supersim.deposit(Deposit(cl_usdc_velo, 0.02))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
