{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# â›“ Chain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import os, asyncio\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from functools import wraps, lru_cache\n",
    "from async_lru import alru_cache\n",
    "from cachetools import cached, TTLCache\n",
    "from typing import List, TypeVar, Callable, Optional, Tuple, Dict\n",
    "from web3 import Web3, HTTPProvider, AsyncWeb3, AsyncHTTPProvider, Account\n",
    "from web3.eth.async_eth import AsyncContract\n",
    "from web3.eth import Contract\n",
    "from web3.manager import RequestManager, RequestBatcher\n",
    "from sugar.config import ChainSettings, make_op_chain_settings, make_base_chain_settings, make_uni_chain_settings, make_lisk_chain_settings\n",
    "from sugar.config import XCHAIN_GAS_LIMIT_UPPERBOUND\n",
    "from sugar.helpers import normalize_address, MAX_UINT256, apply_slippage, get_future_timestamp, ADDRESS_ZERO, chunk, Pair\n",
    "from sugar.helpers import find_all_paths, time_it, atime_it, to_bytes32\n",
    "from sugar.abi import get_abi, bridge_transfer_remote_abi, bridge_get_fee_abi\n",
    "from sugar.token import Token\n",
    "from sugar.pool import LiquidityPool, LiquidityPoolForSwap, LiquidityPoolEpoch\n",
    "from sugar.price import Price\n",
    "from sugar.deposit import Deposit\n",
    "from sugar.quote import QuoteInput, Quote\n",
    "from sugar.swap import setup_planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# monkey patching how web3 handles errors in batched requests\n",
    "# re: https://github.com/ethereum/web3.py/issues/3657\n",
    "original_format_batched_response = RequestManager._format_batched_response\n",
    "def safe_format_batched_response(*args):\n",
    "    try: return original_format_batched_response(*args)\n",
    "    except Exception as e: return e\n",
    "RequestManager._format_batched_response = safe_format_batched_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "T = TypeVar('T')\n",
    "\n",
    "def require_context(f: Callable[..., T]) -> Callable[..., T]:\n",
    "    @wraps(f)\n",
    "    def wrapper(self: 'CommonChain', *args, **kwargs) -> T:\n",
    "        if not self._in_context: raise RuntimeError(\"Chain methods can only be accessed within 'async with' block\")\n",
    "        return f(self, *args, **kwargs)\n",
    "    return wrapper\n",
    "\n",
    "def require_async_context(f: Callable[..., T]) -> Callable[..., T]:\n",
    "    @wraps(f)\n",
    "    async def wrapper(self: 'CommonChain', *args, **kwargs) -> T:\n",
    "        if not self._in_context: raise RuntimeError(\"Chain methods can only be accessed within 'async with' block\")\n",
    "        return await f(self, *args, **kwargs)\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "class CommonChain:\n",
    "    @property\n",
    "    def account(self) -> Account: return self.web3.eth.account.from_key(os.getenv(\"SUGAR_PK\"))\n",
    "\n",
    "    @property\n",
    "    def chain_id(self) -> str: return self.settings.chain_id\n",
    "\n",
    "    @property\n",
    "    def name(self) -> str: return self.settings.chain_name\n",
    "\n",
    "    pools: Optional[List[LiquidityPool]] = None\n",
    "    pools_for_swap: Optional[List[LiquidityPoolForSwap]] = None\n",
    "\n",
    "    def __init__(self, settings: ChainSettings, **kwargs):\n",
    "        self.settings, self._in_context = settings, False\n",
    "\n",
    "        if \"pools\" in kwargs: self.pools = kwargs[\"pools\"]\n",
    "        if \"pools_for_swap\" in kwargs: self.pools_for_swap = kwargs[\"pools_for_swap\"] \n",
    "    \n",
    "    def prepare_set_token_allowance_contract(self, token: Token, contract_wrapper):\n",
    "        ERC20_ABI = [{\n",
    "            \"name\": \"approve\",\n",
    "            \"type\": \"function\",\n",
    "            \"constant\": False,\n",
    "            \"inputs\": [{\"name\": \"spender\", \"type\": \"address\"}, {\"name\": \"amount\", \"type\": \"uint256\"}],\n",
    "            \"outputs\": [{\"name\": \"\", \"type\": \"bool\"}]\n",
    "        }]\n",
    "        return contract_wrapper(address=token.wrapped_token_address or token.token_address, abi=ERC20_ABI)\n",
    "    \n",
    "    def prepare_tokens(self, tokens: List[Tuple], listed_only: bool) -> List[Token]:\n",
    "        native = Token.make_native_token(self.settings.native_token_symbol,\n",
    "                                         self.settings.wrapped_native_token_addr,\n",
    "                                         self.settings.native_token_decimals,\n",
    "                                         chain_id=self.chain_id,\n",
    "                                         chain_name=self.name)\n",
    "        ts = list(map(lambda t: Token.from_tuple(t, chain_id=self.chain_id, chain_name=self.name), tokens))\n",
    "        return [native] + (list(filter(lambda t: t.listed, ts)) if listed_only else ts)\n",
    "    \n",
    "    def find_token_by_address(self, tokens: List[Token], address: str) -> Optional[Token]:\n",
    "        address = normalize_address(address)\n",
    "        return next((t for t in tokens if t.token_address == address), None)\n",
    "\n",
    "    def _get_bridge_token(self, tokens: List[Token]) -> Token:\n",
    "        connector = next((t for t in tokens if t.token_address == self.settings.bridge_token_addr), None)\n",
    "        if not connector: raise ValueError(f\"Superswap bridge token not found on {self.name} chain.\")\n",
    "        return connector\n",
    "\n",
    "    def _prepare_prices(self, tokens: List[Token], rates: List[int]) -> Dict[str, int]:\n",
    "        # token_address => normalized rate\n",
    "        result = {}\n",
    "        # rates are returned multiplied by eth decimals + the difference in decimals to eth\n",
    "        # we want them all normalized to 18 decimals\n",
    "        for cnt, rate in enumerate(rates):\n",
    "            t, eth_decimals = tokens[cnt], self.settings.native_token_decimals\n",
    "            if t.decimals == eth_decimals: nr = rate\n",
    "            elif t.decimals < eth_decimals: nr = rate // (10 ** (eth_decimals - t.decimals))\n",
    "            else: nr = rate * (10 ** (t.decimals - eth_decimals))\n",
    "            result[t.token_address] = nr\n",
    "        return result\n",
    "\n",
    "    def prepare_prices(self, tokens: List[Token], prices: List[int]) -> List[Price]:\n",
    "        \"\"\"Get prices for tokens in target stable token\"\"\"\n",
    "        eth_decimals = self.settings.native_token_decimals\n",
    "        # all rates in EHT: token => rate\n",
    "        rates_in_eth = self._prepare_prices(tokens, prices)\n",
    "        eth_rate, usd_rate = rates_in_eth[self.settings.native_token_symbol], rates_in_eth[self.settings.stable_token_addr]\n",
    "        # this gives us the price of 1 eth in usd with 18 decimals precision\n",
    "        eth_usd_price = (eth_rate * 10 ** eth_decimals) // usd_rate\n",
    "        # finally convert to prices in terms of stable\n",
    "        return [Price(token=t, price=(rates_in_eth[t.token_address] * eth_usd_price // 10 ** eth_decimals) / 10 ** eth_decimals) for t in tokens]\n",
    "    \n",
    "    def prepare_pools(self, pools: List[Tuple], tokens: List[Token], prices: List[Price]) -> List[LiquidityPool]:\n",
    "        tokens, prices = {t.token_address: t for t in tokens}, {price.token.token_address: price for price in prices}\n",
    "        return list(filter(lambda p: p is not None, map(lambda p: LiquidityPool.from_tuple(p, tokens, prices, chain_id=self.chain_id, chain_name=self.name), pools)))\n",
    "    \n",
    "    def prepare_pools_for_swap(self, pools: List[Tuple]) -> List[LiquidityPoolForSwap]:\n",
    "        return list(map(lambda p: LiquidityPoolForSwap.from_tuple(p, chain_id=self.chain_id, chain_name=self.name), pools))\n",
    "\n",
    "    def prepare_pool_epochs(self, epochs: List[Tuple], pools: List[LiquidityPool], tokens: List[Token], prices: List[Price]) -> List[LiquidityPoolEpoch]:\n",
    "        tokens, prices, pools = {t.token_address: t for t in tokens}, {price.token.token_address: price for price in prices}, {p.lp: p for p in pools}\n",
    "        return list(map(lambda p: LiquidityPoolEpoch.from_tuple(p, pools, tokens, prices), epochs))\n",
    "    \n",
    "    def filter_pools_for_swap(self, pools: List[LiquidityPoolForSwap], from_token: Token, to_token: Token) -> List[LiquidityPoolForSwap]:\n",
    "        match_tokens = set(self.settings.connector_tokens_addrs + [from_token.token_address, to_token.token_address])\n",
    "        return list(filter(lambda p: p.token0_address in match_tokens or p.token1_address in match_tokens, pools))\n",
    "    \n",
    "    def paths_to_pools(self, pools: List[LiquidityPoolForSwap], paths: List[List[Tuple]]) -> List[LiquidityPoolForSwap]:\n",
    "        pools_dict = {p.lp: p for p in pools}\n",
    "        return [list(map(lambda p: pools_dict[p[2]], path)) for path in paths]\n",
    "\n",
    "    def prepare_quote_batch(self, from_token: Token, to_token: Token, batcher: RequestBatcher, pools: List[List[LiquidityPoolForSwap]], amount_in: int, paths: List[List[Tuple]]):\n",
    "        inputs = []\n",
    "        for i, path in enumerate(paths):\n",
    "            p = [(p, p.token0_address != path[i][0]) for i, p in enumerate(pools[i])]\n",
    "            q = QuoteInput(from_token=from_token, to_token=to_token, amount_in=amount_in, path=p)\n",
    "            batcher.add(self.quoter.functions.quoteExactInput(q.route.encoded, amount_in))\n",
    "            inputs.append(q)\n",
    "        return batcher, inputs\n",
    "\n",
    "    def prepare_quotes(self, quote_inputs: List[QuoteInput], responses):\n",
    "        if len(responses) != len(quote_inputs): raise ValueError(f\"Number of responses {len(responses)} does not match number of quote inputs {len(quote_inputs)}\")\n",
    "        quotes = []\n",
    "        for i, r in enumerate(responses):\n",
    "            if isinstance(r, Exception): continue\n",
    "            else: quotes.append(Quote(input=quote_inputs[i], amount_out=r[0]))\n",
    "        return quotes\n",
    "    \n",
    "    def get_paths_for_quote(self, from_token: Token, to_token: Token, pools: List[LiquidityPoolForSwap], exclude_tokens: List[str]) -> List[List[Tuple]]:\n",
    "        exclude_tokens_set = set(map(lambda t: normalize_address(t), exclude_tokens))\n",
    "\n",
    "        if from_token.token_address in exclude_tokens: exclude_tokens_set.remove(from_token.token_address)\n",
    "        if to_token.token_address in exclude_tokens: exclude_tokens_set.remove(to_token.token_address)\n",
    "\n",
    "        pairs = [Pair(p.token0_address, p.token1_address, p.lp) for p in pools]\n",
    "        paths = find_all_paths(pairs, from_token.wrapped_token_address or from_token.token_address, to_token.wrapped_token_address or to_token.token_address)\n",
    "        # filter out paths with excluded tokens\n",
    "        return list(filter(lambda p: len(set(map(lambda t: t[0], p)) & exclude_tokens_set) == 0, paths))\n",
    "\n",
    "    def get_pool_paginator(self, batch_size = 5) -> List[List[Tuple]]:\n",
    "        limit, upper_bound = self.settings.pool_page_size, self.settings.pools_count_upper_bound\n",
    "        return chunk(list(map(lambda x: (x, limit), list(range(0, upper_bound, limit)))), batch_size)\n",
    "    \n",
    "    def prepare_price_batcher(self, tokens: List[Token], batch: RequestBatcher):\n",
    "        batches = chunk(tokens, self.settings.price_batch_size)\n",
    "        for b in batches:\n",
    "            batch.add(self.prices.functions.getManyRatesToEthWithCustomConnectors(\n",
    "                list(map(lambda t: t.wrapped_token_address or t.token_address, b)),\n",
    "                False, # use wrappers\n",
    "                self.settings.connector_tokens_addrs,\n",
    "                10 # threshold_filter\n",
    "            ))\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Async chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class AsyncChain(CommonChain):\n",
    "    web3: AsyncWeb3\n",
    "    sugar: AsyncContract\n",
    "    slipstream: AsyncContract\n",
    "    router: AsyncContract\n",
    "    prices: AsyncContract\n",
    "    quoter: AsyncContract\n",
    "    swapper: AsyncContract\n",
    "\n",
    "\n",
    "    async def __aenter__(self):\n",
    "        \"\"\"Async context manager entry\"\"\"\n",
    "        self._in_context = True\n",
    "        self.web3 = AsyncWeb3(AsyncHTTPProvider(self.settings.rpc_uri))\n",
    "        self.sugar = self.web3.eth.contract(address=self.settings.sugar_contract_addr, abi=get_abi(\"sugar\"))\n",
    "        self.sugar_rewards = self.web3.eth.contract(address=self.settings.sugar_rewards_contract_addr, abi=get_abi(\"sugar_rewards\"))\n",
    "        self.slipstream = self.web3.eth.contract(address=self.settings.slipstream_contract_addr, abi=get_abi(\"slipstream\"))\n",
    "        self.prices = self.web3.eth.contract(address=self.settings.price_oracle_contract_addr, abi=get_abi(\"price_oracle\"))\n",
    "        self.router = self.web3.eth.contract(address=self.settings.router_contract_addr, abi=get_abi(\"router\"))\n",
    "        self.quoter = self.web3.eth.contract(address=self.settings.quoter_contract_addr, abi=get_abi(\"quoter\"))\n",
    "        self.swapper = self.web3.eth.contract(address=self.settings.swapper_contract_addr, abi=get_abi(\"swapper\"))\n",
    "        if hasattr(self.settings, \"interchain_router_contract_addr\"):\n",
    "            # TODO: clean this up when interchain jazz is fully implemented\n",
    "            self.ica_router = self.web3.eth.contract(address=self.settings.interchain_router_contract_addr, abi=get_abi(\"interchain_router\"))\n",
    "\n",
    "        # set up caching for price oracle\n",
    "        self._get_prices = alru_cache(ttl=self.settings.pricing_cache_timeout_seconds)(self._get_prices)\n",
    "\n",
    "        return self\n",
    "\n",
    "    async def __aexit__(self, exc_type, exc_val, exc_tb):\n",
    "        \"\"\"Async context manager exit\"\"\"\n",
    "        self._in_context = False\n",
    "        await self.web3.provider.disconnect()\n",
    "        return None\n",
    "\n",
    "    async def apaginate(self, f: Callable):\n",
    "        async def process_batch(batch: List[Tuple]):\n",
    "            async with self.web3.batch_requests() as batcher:\n",
    "                for offset, limit in batch: batcher.add(f(limit, offset))\n",
    "                return sum(await batcher.async_execute(), [])\n",
    "        return sum(await asyncio.gather(*[process_batch(batch) for batch in self.get_pool_paginator()]), [])\n",
    "    \n",
    "    @require_async_context\n",
    "    async def get_bridge_fee(self, domain: int) -> int:\n",
    "        contract = self.web3.eth.contract(address=self.settings.bridge_contract_addr, abi=bridge_get_fee_abi)\n",
    "        return await contract.functions.quoteGasPayment(domain).call()\n",
    "\n",
    "    @require_async_context\n",
    "    async def _internal_bridge_token(self, from_token: Token, destination_token: Token, amount: int, domain: int):\n",
    "        # XX: marking this API as \"internal\" for now\n",
    "        # TODO: remove destination_domain when get domain API stabilizes\n",
    "        c = self.web3.eth.contract(address=self.settings.bridge_contract_addr, abi=bridge_transfer_remote_abi)\n",
    "        await self.set_token_allowance(from_token, self.settings.bridge_contract_addr, amount)\n",
    "        return await self.sign_and_send_tx(c.functions.transferRemote(domain, to_bytes32(self.account.address), amount), value=await self.get_bridge_fee(domain))\n",
    "    \n",
    "    @require_async_context\n",
    "    async def get_xchain_fee(self, destination_domain: int) -> int:\n",
    "        return await self.ica_router.functions.quoteGasForCommitReveal(destination_domain, XCHAIN_GAS_LIMIT_UPPERBOUND).call()\n",
    "\n",
    "    @require_async_context\n",
    "    async def get_remote_interchain_account(self, destination_domain: int):\n",
    "        abi = [{\n",
    "            \"name\": \"getRemoteInterchainAccount\",\n",
    "            \"type\": \"function\",\n",
    "            \"stateMutability\": \"view\",\n",
    "            \"inputs\": [\n",
    "                {\n",
    "                    \"name\": \"\",\n",
    "                    \"type\": \"uint32\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"\",\n",
    "                    \"type\": \"address\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"\",\n",
    "                    \"type\": \"bytes32\"\n",
    "                }\n",
    "            ],\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                \"name\": \"userICA\",\n",
    "                \"type\": \"address\"\n",
    "                }\n",
    "            ]\n",
    "        }]\n",
    "        contract = self.web3.eth.contract(address=self.settings.interchain_router_contract_addr, abi=abi)\n",
    "        return await contract.functions.getRemoteInterchainAccount(\n",
    "            destination_domain,\n",
    "            self.settings.swapper_contract_addr,\n",
    "            to_bytes32(self.account.address),\n",
    "        ).call()\n",
    "\n",
    "    @require_async_context\n",
    "    async def get_ica_hook(self): return await self.ica_router.functions.hook().call()\n",
    "\n",
    "    @require_async_context\n",
    "    async def get_user_ica_balance(self, user_ica: str) -> int:\n",
    "        abi = [{\n",
    "            \"type\": 'function',\n",
    "            \"name\": 'balanceOf',\n",
    "            \"stateMutability\": 'view',\n",
    "            \"inputs\": [\n",
    "                {\n",
    "                    \"name\": 'account',\n",
    "                    \"type\": 'address',\n",
    "                }\n",
    "            ],\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"type\": 'uint256',\n",
    "                }\n",
    "            ]\n",
    "        }]\n",
    "        contract = self.web3.eth.contract(address=self.settings.bridge_token_addr, abi=abi)\n",
    "        return await contract.functions.balanceOf(user_ica).call()\n",
    "\n",
    "    @require_async_context\n",
    "    @alru_cache(maxsize=None)\n",
    "    async def get_all_tokens(self, listed_only: bool = False) -> List[Token]:\n",
    "        def get_tokens(limit, offset): return self.sugar.functions.tokens(limit, offset, ADDRESS_ZERO, [])\n",
    "        return self.prepare_tokens(await self.apaginate(get_tokens), listed_only)\n",
    "    \n",
    "    @require_async_context\n",
    "    async def get_token(self, address: str) -> Optional[Token]:\n",
    "        \"\"\"Get token by address\"\"\"\n",
    "        return self.find_token_by_address(await self.get_all_tokens(), address)\n",
    "\n",
    "    @require_async_context\n",
    "    async def get_bridge_token(self) -> Token: return self._get_bridge_token(await self.get_all_tokens())\n",
    "\n",
    "    async def _get_prices(self, tokens: Tuple[Token]):\n",
    "        async with self.web3.batch_requests() as batch:\n",
    "            batch = self.prepare_price_batcher(tokens=list(tokens), batch=batch)\n",
    "            return sum(await batch.async_execute(), [])\n",
    "\n",
    "    @require_async_context\n",
    "    async def get_prices(self, tokens: List[Token]) -> List[Price]:\n",
    "        \"\"\"Get prices for tokens in target stable token\"\"\"\n",
    "        return self.prepare_prices(tokens, await self._get_prices(tuple(tokens)))\n",
    "\n",
    "    @alru_cache(maxsize=None)\n",
    "    async def get_raw_pools(self, for_swaps: bool):\n",
    "        return await self.apaginate(self.sugar.functions.forSwaps if for_swaps else self.sugar.functions.all)\n",
    "    \n",
    "    @require_async_context\n",
    "    async def get_pools(self, for_swaps: bool = False) -> List[LiquidityPool]:\n",
    "        pools = await self.get_raw_pools(for_swaps)\n",
    "        if not for_swaps:\n",
    "            tokens = await self.get_all_tokens()\n",
    "            return self.prepare_pools(pools, tokens, await self.get_prices(tokens))\n",
    "        else: return self.prepare_pools_for_swap(pools)\n",
    "    \n",
    "    @require_async_context\n",
    "    @alru_cache(maxsize=None)\n",
    "    async def get_pool_by_address(self, address: str) -> Optional[LiquidityPool]:\n",
    "        try:\n",
    "            p = await self.sugar.functions.byAddress(address).call()\n",
    "        except: return None\n",
    "        tokens = await self.get_all_tokens(listed_only=False)\n",
    "        return self.prepare_pools([p], tokens, await self.get_prices(tokens))[0]\n",
    "\n",
    "    @require_async_context\n",
    "    @alru_cache(maxsize=None)\n",
    "    async def get_pool_epochs(self, lp: str, offset: int = 0, limit: int = 10) -> List[LiquidityPoolEpoch]:\n",
    "        tokens, pools = await self.get_all_tokens(listed_only=False), await self.get_pools()\n",
    "        prices = await self.get_prices(tokens)\n",
    "        r = await self.sugar_rewards.functions.epochsByAddress(limit, offset, normalize_address(lp)).call()\n",
    "        return self.prepare_pool_epochs(r, pools, tokens, prices)\n",
    "\n",
    "    @require_async_context\n",
    "    @alru_cache(maxsize=None)\n",
    "    async def get_latest_pool_epochs(self) -> List[LiquidityPoolEpoch]:\n",
    "        tokens, pools = await self.get_all_tokens(listed_only=False), await self.get_pools()\n",
    "        prices = await self.get_prices(tokens)\n",
    "        return self.prepare_pool_epochs(await self.apaginate(self.sugar_rewards.functions.epochsLatest), pools, tokens, prices)\n",
    "    \n",
    "    @require_async_context\n",
    "    async def get_pools_for_swaps(self) -> List[LiquidityPoolForSwap]: return await self.get_pools(for_swaps=True)\n",
    "\n",
    "    @require_async_context\n",
    "    async def _get_quotes_for_paths(self, from_token: Token, to_token: Token, amount_in: int, pools: List[LiquidityPoolForSwap], paths: List[List[Tuple]]) -> List[Optional[Quote]]:\n",
    "        path_pools = self.paths_to_pools(pools, paths)\n",
    "        async with self.web3.batch_requests() as batch:\n",
    "            batch, inputs = self.prepare_quote_batch(from_token, to_token, batch, path_pools, amount_in, paths)\n",
    "            return self.prepare_quotes(inputs, await batch.async_execute())\n",
    "\n",
    "    @require_async_context\n",
    "    async def get_quote(self, from_token: Token, to_token: Token, amount: int, filter_quotes: Optional[Callable[[Quote], bool]] = None) -> Optional[Quote]:\n",
    "        pools = self.filter_pools_for_swap(from_token=from_token, to_token=to_token, pools=await self.get_pools_for_swaps())\n",
    "        paths = self.get_paths_for_quote(from_token, to_token, pools, self.settings.excluded_tokens_addrs)\n",
    "        quotes = sum(await asyncio.gather(*[self._get_quotes_for_paths(from_token, to_token, amount, pools, paths) for paths in chunk(paths, 500)]), [])\n",
    "        quotes = list(filter(lambda q: q is not None, quotes))\n",
    "        if filter_quotes is not None: quotes = list(filter(filter_quotes, quotes))\n",
    "        return max(quotes, key=lambda q: q.amount_out) if len(quotes) > 0 else None\n",
    "    \n",
    "    @require_async_context\n",
    "    async def swap(self, from_token: Token, to_token: Token, amount: int, slippage: Optional[float] = None):\n",
    "        q = await self.get_quote(from_token, to_token, amount=amount)\n",
    "        if not q: raise ValueError(\"No quotes found\")\n",
    "        return await self.swap_from_quote(q, slippage=slippage)\n",
    "        \n",
    "    @require_async_context\n",
    "    async def swap_from_quote(self, quote: Quote, slippage: Optional[float] = None):\n",
    "        swapper_contract_addr, from_token = self.settings.swapper_contract_addr, quote.from_token\n",
    "        planner = setup_planner(quote=quote, slippage=slippage if slippage is not None else self.settings.swap_slippage, account=self.account.address, router_address=swapper_contract_addr)\n",
    "        await self.set_token_allowance(from_token, swapper_contract_addr, quote.input.amount_in)\n",
    "        value = quote.input.amount_in if from_token.wrapped_token_address else 0\n",
    "        return await self.sign_and_send_tx(self.swapper.functions.execute(*[planner.commands, planner.inputs]), value=value)\n",
    "\n",
    "    @require_async_context\n",
    "    async def set_token_allowance(self, token: Token, addr: str, amount: int):\n",
    "        token_contract = self.prepare_set_token_allowance_contract(token, self.web3.eth.contract)\n",
    "        return await self.sign_and_send_tx(token_contract.functions.approve(addr, amount))\n",
    "\n",
    "    @require_async_context\n",
    "    async def check_token_allowance(self, token: Token, addr: str) -> int:\n",
    "        ERC20_ABI = [{\n",
    "            \"name\": \"allowance\",\n",
    "            \"type\": \"function\",\n",
    "            \"constant\": True,\n",
    "            \"inputs\": [{\"name\": \"owner\", \"type\": \"address\"}, {\"name\": \"spender\", \"type\": \"address\"}],\n",
    "            \"outputs\": [{\"name\": \"\", \"type\": \"uint256\"}]\n",
    "        }]\n",
    "        token_contract = self.web3.eth.contract(address=token.wrapped_token_address or token.token_address, abi=ERC20_ABI)\n",
    "        return await token_contract.functions.allowance(self.account.address, addr).call()\n",
    "\n",
    "    @require_async_context\n",
    "    async def sign_and_send_tx(self, tx, value: int = 0, wait: bool = True):\n",
    "        spender = self.account.address\n",
    "        tx = await tx.build_transaction({ 'from': spender, 'value': value, 'nonce': await self.web3.eth.get_transaction_count(spender, \"pending\") })\n",
    "        signed_tx = self.account.sign_transaction(tx)\n",
    "        tx_hash = await self.web3.eth.send_raw_transaction(signed_tx.raw_transaction)\n",
    "        return await self.web3.eth.wait_for_transaction_receipt(tx_hash) if wait else tx_hash\n",
    "    \n",
    "    @require_async_context\n",
    "    async def deposit(self, deposit: Deposit, delay_in_minutes: float = 30, slippage: float = 0.01):\n",
    "        amount_token0, pool, router_contract_addr = deposit.amount_token0, deposit.pool, self.settings.router_contract_addr\n",
    "        print(f\"gonna deposit {amount_token0} {pool.token0.symbol} into {pool.symbol} from {self.account.address}\")\n",
    "        [token0_amount, token1_amount, _] = await self.router.functions.quoteAddLiquidity(\n",
    "            pool.token0.token_address,\n",
    "            pool.token1.token_address,\n",
    "            pool.is_stable,\n",
    "            pool.factory,\n",
    "            amount_token0,\n",
    "            MAX_UINT256\n",
    "        ).call()\n",
    "        print(f\"Quote: {pool.token0.symbol} {token0_amount / 10 ** pool.token0.decimals} -> {pool.token1.symbol} {token1_amount / 10 ** pool.token1.decimals}\")\n",
    "\n",
    "        # set up allowance for both tokens\n",
    "        print(f\"setting up allowance for {pool.token0.symbol}\")\n",
    "        await self.set_token_allowance(pool.token0, router_contract_addr, token0_amount)\n",
    "\n",
    "        print(f\"setting up allowance for {pool.token1.symbol}\")\n",
    "        await self.set_token_allowance(pool.token1, router_contract_addr, token1_amount)\n",
    "\n",
    "        # check allowances\n",
    "        token0_allowance = await self.check_token_allowance(pool.token0, router_contract_addr)\n",
    "        token1_allowance = await self.check_token_allowance(pool.token1, router_contract_addr)\n",
    "\n",
    "        print(f\"allowances: {token0_allowance}, {token1_allowance}\")\n",
    "\n",
    "        # adding liquidity\n",
    "\n",
    "        # if token 0 is native, use addLiquidityETH instead of standard addLiquidity\n",
    "        if pool.token0.token_address == self.settings.wrapped_native_token_addr:\n",
    "            params = [\n",
    "                pool.token1.token_address,\n",
    "                pool.is_stable,\n",
    "                token1_amount,\n",
    "                apply_slippage(token1_amount, slippage),\n",
    "                apply_slippage(token0_amount, slippage),\n",
    "                self.account.address,\n",
    "                get_future_timestamp(delay_in_minutes)\n",
    "            ]\n",
    "            print(f\"adding liquidity with params: {params}\")\n",
    "            return await self.sign_and_send_tx(self.router.functions.addLiquidityETH(*params), value=token0_amount)\n",
    "        \n",
    "        # token 1 is native, use addLiquidityETH instead of standard addLiquidity\n",
    "        if pool.token1.token_address == self.settings.wrapped_native_token_addr:\n",
    "            params = [\n",
    "                pool.token0.token_address,\n",
    "                pool.is_stable,\n",
    "                token0_amount,\n",
    "                apply_slippage(token0_amount, slippage),\n",
    "                apply_slippage(token1_amount, slippage),\n",
    "                self.account.address,\n",
    "                get_future_timestamp(delay_in_minutes)\n",
    "            ]\n",
    "            print(f\"adding liquidity with params: {params}\")\n",
    "            return await self.sign_and_send_tx(self.router.functions.addLiquidityETH(*params), value=token1_amount)\n",
    "\n",
    "        params = [\n",
    "            pool.token0.token_address,\n",
    "            pool.token1.token_address,\n",
    "            pool.is_stable,\n",
    "            token0_amount,\n",
    "            token1_amount,\n",
    "            apply_slippage(token0_amount, slippage),\n",
    "            apply_slippage(token1_amount, slippage),\n",
    "            self.account.address,\n",
    "            get_future_timestamp(delay_in_minutes)\n",
    "        ]\n",
    "\n",
    "        print(f\"adding liquidity with params: {params}\")\n",
    "\n",
    "        return await self.sign_and_send_tx(self.router.functions.addLiquidity(*params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sync chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class Chain(CommonChain):\n",
    "    web3: Web3\n",
    "    sugar: Contract\n",
    "    router: Contract\n",
    "    slipstream: Contract\n",
    "    prices: Contract\n",
    "    quoter: Contract\n",
    "    swapper: Contract\n",
    "\n",
    "    def __enter__(self):\n",
    "        \"\"\"Sync context manager entry\"\"\"\n",
    "        self._in_context = True\n",
    "        self.web3 = Web3(HTTPProvider(self.settings.rpc_uri))\n",
    "        self.sugar = self.web3.eth.contract(address=self.settings.sugar_contract_addr, abi=get_abi(\"sugar\"))\n",
    "        self.sugar_rewards = self.web3.eth.contract(address=self.settings.sugar_rewards_contract_addr, abi=get_abi(\"sugar_rewards\"))\n",
    "        self.slipstream = self.web3.eth.contract(address=self.settings.slipstream_contract_addr, abi=get_abi(\"slipstream\"))\n",
    "        self.prices = self.web3.eth.contract(address=self.settings.price_oracle_contract_addr, abi=get_abi(\"price_oracle\"))\n",
    "        self.router = self.web3.eth.contract(address=self.settings.router_contract_addr, abi=get_abi(\"router\"))\n",
    "        self.quoter = self.web3.eth.contract(address=self.settings.quoter_contract_addr, abi=get_abi(\"quoter\"))\n",
    "        self.swapper = self.web3.eth.contract(address=self.settings.swapper_contract_addr, abi=get_abi(\"swapper\"))\n",
    "\n",
    "        if hasattr(self.settings, \"interchain_router_contract_addr\"):\n",
    "            # TODO: clean this up when interchain jazz is fully implemented\n",
    "            self.ica_router = self.web3.eth.contract(address=self.settings.interchain_router_contract_addr, abi=get_abi(\"interchain_router\"))\n",
    "\n",
    "        # set up caching for price oracle\n",
    "        self._get_prices = cached(TTLCache(ttl=self.settings.pricing_cache_timeout_seconds, maxsize=self.settings.price_batch_size * 10))(self._get_prices)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        \"\"\"Sync context manager exit\"\"\"\n",
    "        self._in_context = False\n",
    "        return None\n",
    "    \n",
    "    def paginate(self, f: Callable):\n",
    "        results, batches = [], self.get_pool_paginator()\n",
    "\n",
    "        def process_batch(batch: List[Tuple]):\n",
    "            with self.web3.batch_requests() as batcher:\n",
    "                for offset, limit in batch: batcher.add(f(limit, offset))\n",
    "                return sum(batcher.execute(), [])\n",
    "\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=self.settings.threading_max_workers) as executor:\n",
    "            future_to_batch = {\n",
    "                executor.submit(process_batch, batch): batch\n",
    "                for batch in batches\n",
    "            }\n",
    "            for future in as_completed(future_to_batch):\n",
    "                try: results.extend(future.result())\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing path chunk: {e}\")\n",
    "                    continue\n",
    "\n",
    "        return results\n",
    "\n",
    "    @require_context\n",
    "    def get_bridge_fee(self, domain: int) -> int:\n",
    "        contract = self.web3.eth.contract(address=self.settings.bridge_contract_addr, abi=bridge_get_fee_abi)\n",
    "        return contract.functions.quoteGasPayment(domain).call()\n",
    "    \n",
    "    @require_context\n",
    "    def _internal_bridge_token(self, from_token: Token, destination_token: Token, amount: int, domain: int):\n",
    "        # XX: marking this API as \"internal\" for now\n",
    "        # TODO: remove destination_domain when get domain API stabilizes\n",
    "        c = self.web3.eth.contract(address=self.settings.bridge_contract_addr, abi=bridge_transfer_remote_abi)\n",
    "        self.set_token_allowance(from_token, self.settings.bridge_contract_addr, amount)\n",
    "        return self.sign_and_send_tx(c.functions.transferRemote(domain, to_bytes32(self.account.address), amount), value=self.get_bridge_fee(domain))\n",
    "\n",
    "    @require_context\n",
    "    def get_xchain_fee(self, destination_domain: int) -> int:\n",
    "        return self.ica_router.functions.quoteGasForCommitReveal(destination_domain, XCHAIN_GAS_LIMIT_UPPERBOUND).call()\n",
    "\n",
    "    @require_context\n",
    "    def get_remote_interchain_account(self, destination_domain: int):\n",
    "        abi = [{\n",
    "            \"name\": \"getRemoteInterchainAccount\",\n",
    "            \"type\": \"function\",\n",
    "            \"stateMutability\": \"view\",\n",
    "            \"inputs\": [\n",
    "                {\n",
    "                    \"name\": \"\",\n",
    "                    \"type\": \"uint32\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"\",\n",
    "                    \"type\": \"address\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"\",\n",
    "                    \"type\": \"bytes32\"\n",
    "                }\n",
    "            ],\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                \"name\": \"userICA\",\n",
    "                \"type\": \"address\"\n",
    "                }\n",
    "            ]\n",
    "        }]\n",
    "        contract = self.web3.eth.contract(address=self.settings.interchain_router_contract_addr, abi=abi)\n",
    "        return contract.functions.getRemoteInterchainAccount(\n",
    "            destination_domain,\n",
    "            self.settings.swapper_contract_addr,\n",
    "            to_bytes32(self.account.address),\n",
    "        ).call()\n",
    "\n",
    "    @require_context\n",
    "    def get_ica_hook(self): return self.ica_router.functions.hook().call()\n",
    "\n",
    "    @require_context\n",
    "    def get_user_ica_balance(self, user_ica: str) -> int:\n",
    "        abi = [{\n",
    "            \"type\": 'function',\n",
    "            \"name\": 'balanceOf',\n",
    "            \"stateMutability\": 'view',\n",
    "            \"inputs\": [\n",
    "                {\n",
    "                    \"name\": 'account',\n",
    "                    \"type\": 'address',\n",
    "                }\n",
    "            ],\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"type\": 'uint256',\n",
    "                }\n",
    "            ]\n",
    "        }]\n",
    "        contract = self.web3.eth.contract(address=self.settings.bridge_token_addr, abi=abi)\n",
    "        return contract.functions.balanceOf(user_ica).call()\n",
    "\n",
    "    @require_context\n",
    "    def sign_and_send_tx(self, tx, value: int = 0, wait: bool = True):\n",
    "        spender = self.account.address\n",
    "        tx = tx.build_transaction({ 'from': spender, 'value': value, 'nonce': self.web3.eth.get_transaction_count(spender, \"pending\") })\n",
    "        signed_tx = self.account.sign_transaction(tx)\n",
    "        tx_hash = self.web3.eth.send_raw_transaction(signed_tx.raw_transaction)\n",
    "        return self.web3.eth.wait_for_transaction_receipt(tx_hash) if wait else tx_hash\n",
    "    \n",
    "    @require_context\n",
    "    def set_token_allowance(self, token: Token, addr: str, amount: int):\n",
    "        token_contract = self.prepare_set_token_allowance_contract(token, self.web3.eth.contract)\n",
    "        return self.sign_and_send_tx(token_contract.functions.approve(addr, amount))\n",
    "\n",
    "    @require_context\n",
    "    @lru_cache(maxsize=None)\n",
    "    def get_all_tokens(self, listed_only: bool = False) -> List[Token]:\n",
    "        def get_tokens(limit, offset): return self.sugar.functions.tokens(limit, offset, ADDRESS_ZERO, [])\n",
    "        return self.prepare_tokens(self.paginate(get_tokens), listed_only)\n",
    "\n",
    "    @require_context\n",
    "    def get_token(self, address: str) -> Optional[Token]:\n",
    "        \"\"\"Get token by address\"\"\"\n",
    "        return self.find_token_by_address(self.get_all_tokens(), address)\n",
    "\n",
    "    @require_context\n",
    "    def get_bridge_token(self) -> Token: return self._get_bridge_token(self.get_all_tokens())\n",
    "\n",
    "    def _get_prices(self, tokens: Tuple[Token]) -> List[int]:\n",
    "        # token_address => normalized rate\n",
    "        with self.web3.batch_requests() as batch:\n",
    "            batch = self.prepare_price_batcher(tokens=list(tokens), batch=batch)\n",
    "            return sum(batch.execute(), [])\n",
    "\n",
    "    @require_context\n",
    "    def get_prices(self, tokens: List[Token]) -> List[Price]:\n",
    "        \"\"\"Get prices for tokens in target stable token\"\"\"\n",
    "        return self.prepare_prices(tokens, self._get_prices(tuple(tokens)))\n",
    "    \n",
    "    @lru_cache(maxsize=None)\n",
    "    def get_raw_pools(self, for_swaps: bool):\n",
    "        return self.paginate(self.sugar.functions.forSwaps if for_swaps else self.sugar.functions.all)\n",
    "\n",
    "    @require_context\n",
    "    def get_pools(self, for_swaps: bool = False) -> List[LiquidityPool]:\n",
    "        pools = self.get_raw_pools(for_swaps)\n",
    "        if not for_swaps:\n",
    "            tokens = self.get_all_tokens(listed_only=False)\n",
    "            return self.prepare_pools(pools, tokens, self.get_prices(tokens))\n",
    "        else: return self.prepare_pools_for_swap(pools)\n",
    "\n",
    "    @require_context\n",
    "    @lru_cache(maxsize=None)\n",
    "    def get_pool_by_address(self, address: str) -> Optional[LiquidityPool]:\n",
    "        try:\n",
    "            p = self.sugar.functions.byAddress(address).call()\n",
    "        except: return None\n",
    "        tokens = self.get_all_tokens(listed_only=False)\n",
    "        return self.prepare_pools([p], tokens, self.get_prices(tokens))[0]\n",
    "    \n",
    "    @require_context\n",
    "    def get_pools_for_swaps(self) -> List[LiquidityPoolForSwap]: return self.get_pools(for_swaps=True)\n",
    "\n",
    "    @require_context\n",
    "    @lru_cache(maxsize=None)\n",
    "    def get_pool_epochs(self, lp: str, offset: int = 0, limit: int = 10) -> List[LiquidityPoolEpoch]:\n",
    "        tokens, pools = self.get_all_tokens(listed_only=False), self.get_pools()\n",
    "        prices = self.get_prices(tokens)\n",
    "        r = self.sugar_rewards.functions.epochsByAddress(limit, offset, normalize_address(lp)).call()\n",
    "        return self.prepare_pool_epochs(r, pools, tokens, prices)\n",
    "\n",
    "    @require_context\n",
    "    @lru_cache(maxsize=None)\n",
    "    def get_latest_pool_epochs(self) -> List[LiquidityPoolEpoch]:\n",
    "        tokens, pools = self.get_all_tokens(listed_only=False), self.get_pools()\n",
    "        prices = self.get_prices(tokens)\n",
    "        return self.prepare_pool_epochs(self.paginate(self.sugar_rewards.functions.epochsLatest), pools, tokens, prices)\n",
    "\n",
    "    @require_context\n",
    "    def _get_quotes_for_paths(self, from_token: Token, to_token: Token, amount_in: int, pools: List[LiquidityPoolForSwap], paths: List[List[Tuple]]) -> List[Optional[Quote]]:\n",
    "        path_pools = self.paths_to_pools(pools, paths)\n",
    "        with self.web3.batch_requests() as batch:\n",
    "            batch, inputs = self.prepare_quote_batch(from_token, to_token, batch, path_pools, amount_in, paths)\n",
    "            return self.prepare_quotes(inputs, batch.execute())\n",
    "    \n",
    "    @require_context\n",
    "    def get_quote(self, from_token: Token, to_token: Token, amount: int, filter_quotes: Optional[Callable[[Quote], bool]] = None) -> Optional[Quote]:\n",
    "        pools = self.filter_pools_for_swap(from_token=from_token, to_token=to_token, pools=self.get_pools_for_swaps())\n",
    "        paths = self.get_paths_for_quote(from_token, to_token, pools, self.settings.excluded_tokens_addrs)\n",
    "        path_chunks = list(chunk(paths, 500))\n",
    "\n",
    "        def get_quotes_for_chunk(paths_chunk):\n",
    "            return self._get_quotes_for_paths(from_token, to_token, amount, pools, paths_chunk)\n",
    "        \n",
    "        all_quotes = []\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=self.settings.threading_max_workers) as executor:\n",
    "            # Submit all chunk processing tasks\n",
    "            future_to_chunk = {\n",
    "                executor.submit(get_quotes_for_chunk, chunk_paths): chunk_paths \n",
    "                for chunk_paths in path_chunks\n",
    "            }\n",
    "            \n",
    "            # Collect results as they complete\n",
    "            for future in as_completed(future_to_chunk):\n",
    "                try:\n",
    "                    all_quotes.extend(future.result())\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing path chunk: {e}\")\n",
    "                    continue\n",
    "\n",
    "        # Filter out None quotes\n",
    "        all_quotes = [q for q in all_quotes if q is not None]\n",
    "    \n",
    "        if filter_quotes is not None:  all_quotes = list(filter(filter_quotes, all_quotes))\n",
    "\n",
    "        return max(all_quotes, key=lambda q: q.amount_out) if len(all_quotes) > 0 else None\n",
    "    \n",
    "    @require_context\n",
    "    def swap(self, from_token: Token, to_token: Token, amount: int, slippage: Optional[float] = None):\n",
    "        q = self.get_quote(from_token, to_token, amount=amount)\n",
    "        if not q: raise ValueError(\"No quotes found\")\n",
    "        return self.swap_from_quote(q, slippage=slippage)\n",
    "        \n",
    "    @require_context\n",
    "    def swap_from_quote(self, quote: Quote, slippage: Optional[float] = None):\n",
    "        swapper_contract_addr, from_token = self.settings.swapper_contract_addr, quote.from_token\n",
    "        planner = setup_planner(quote=quote, slippage=slippage if slippage is not None else self.settings.swap_slippage, account=self.account.address, router_address=swapper_contract_addr)\n",
    "        self.set_token_allowance(from_token, swapper_contract_addr, quote.input.amount_in)\n",
    "        value = quote.input.amount_in if from_token.wrapped_token_address else 0\n",
    "        return self.sign_and_send_tx(self.swapper.functions.execute(*[planner.commands, planner.inputs]), value=value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OP Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "_op_settings = make_op_chain_settings()\n",
    "\n",
    "class OPChainCommon():\n",
    "    usdc: Token = Token(chain_id=_op_settings.chain_id, chain_name=_op_settings.chain_name,\n",
    "                        token_address='0x0b2C639c533813f4Aa9D7837CAf62653d097Ff85', symbol='USDC',\n",
    "                        decimals=6, listed=True, wrapped_token_address=None)\n",
    "    velo: Token = Token(chain_id=_op_settings.chain_id, chain_name=_op_settings.chain_name,\n",
    "                        token_address='0x9560e827aF36c94D2Ac33a39bCE1Fe78631088Db', symbol='VELO', decimals=18, listed=True, wrapped_token_address=None)\n",
    "    eth: Token = Token(chain_id=_op_settings.chain_id, chain_name=_op_settings.chain_name,\n",
    "                       token_address='ETH', symbol='ETH', decimals=18, listed=True, wrapped_token_address='0x4200000000000000000000000000000000000006') \n",
    "    o_usdt: Token = Token(chain_id=_op_settings.chain_id, chain_name=_op_settings.chain_name,\n",
    "                         token_address='0x1217BfE6c773EEC6cc4A38b5Dc45B92292B6E189', symbol='oUSDT',\n",
    "                         decimals=6, listed=True, wrapped_token_address=None)\n",
    "\n",
    "class AsyncOPChain(AsyncChain, OPChainCommon):\n",
    "    def __init__(self, **kwargs): super().__init__(make_op_chain_settings(**kwargs), **kwargs)\n",
    "\n",
    "class OPChain(Chain, OPChainCommon):\n",
    "    def __init__(self, **kwargs): super().__init__(make_op_chain_settings(**kwargs), **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "_base_settings = make_base_chain_settings()\n",
    "\n",
    "class BaseChainCommon():\n",
    "    usdc: Token = Token(chain_id=_base_settings.chain_id, chain_name=_base_settings.chain_name,\n",
    "                        token_address='0x833589fCD6eDb6E08f4c7C32D4f71b54bdA02913', symbol='USDC', decimals=6, listed=True, wrapped_token_address=None)\n",
    "    aero: Token = Token(chain_id=_base_settings.chain_id, chain_name=_base_settings.chain_name,\n",
    "                        token_address='0x940181a94A35A4569E4529A3CDfB74e38FD98631', symbol='AERO', decimals=18, listed=True, wrapped_token_address=None)\n",
    "    eth: Token = Token(chain_id=_base_settings.chain_id, chain_name=_base_settings.chain_name,\n",
    "                       token_address='ETH', symbol='ETH', decimals=18, listed=True, wrapped_token_address='0x4200000000000000000000000000000000000006')\n",
    "    \n",
    "class AsyncBaseChain(AsyncChain, BaseChainCommon):\n",
    "    def __init__(self, **kwargs): super().__init__(make_base_chain_settings(**kwargs), **kwargs)\n",
    "\n",
    "class BaseChain(Chain, BaseChainCommon):\n",
    "    def __init__(self, **kwargs): super().__init__(make_base_chain_settings(**kwargs), **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lisk Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class LiskChainCommon():\n",
    "    o_usdt: Token = Token(chain_id='1135', chain_name='Lisk', token_address='0x1217BfE6c773EEC6cc4A38b5Dc45B92292B6E189', symbol='oUSDT', decimals=6, listed=True, wrapped_token_address=None)\n",
    "    lsk: Token = Token(chain_id='1135', chain_name='Lisk', token_address='0xac485391EB2d7D88253a7F1eF18C37f4242D1A24', symbol='LSK', decimals=18, listed=True, wrapped_token_address=None)\n",
    "    eth: Token = Token(chain_id='1135', chain_name='Lisk', token_address='ETH', symbol='ETH', decimals=18, listed=True, wrapped_token_address='0x4200000000000000000000000000000000000006')\n",
    "    usdt: Token = Token(chain_id='1135', chain_name='Lisk', token_address='0x05D032ac25d322df992303dCa074EE7392C117b9', symbol='USDT', decimals=6, listed=True, wrapped_token_address=None)\n",
    "\n",
    "class AsyncLiskChain(AsyncChain, LiskChainCommon):\n",
    "    def __init__(self, **kwargs): super().__init__(make_lisk_chain_settings(**kwargs), **kwargs)\n",
    "\n",
    "class LiskChain(Chain, LiskChainCommon):\n",
    "    def __init__(self, **kwargs): super().__init__(make_lisk_chain_settings(**kwargs), **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uni Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class UniChainCommon():\n",
    "    o_usdt: Token = Token(chain_id='130', chain_name='Uni', token_address='0x1217BfE6c773EEC6cc4A38b5Dc45B92292B6E189', symbol='oUSDT', decimals=6, listed=True, wrapped_token_address=None)\n",
    "    usdc: Token = Token(chain_id='130', chain_name='Uni', token_address='0x078D782b760474a361dDA0AF3839290b0EF57AD6', symbol='USDC', decimals=6, listed=True, wrapped_token_address=None)\n",
    "    \n",
    "class AsyncUniChain(AsyncChain, UniChainCommon):\n",
    "    def __init__(self, **kwargs): super().__init__(make_uni_chain_settings(**kwargs), **kwargs)\n",
    "\n",
    "class UniChain(Chain, UniChainCommon):\n",
    "    def __init__(self, **kwargs): super().__init__(make_uni_chain_settings(**kwargs), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_chain(chain_id: str, **kwargs) -> Chain:\n",
    "    if chain_id == '10': return OPChain(**kwargs)\n",
    "    elif chain_id == '8453': return BaseChain(**kwargs)\n",
    "    elif chain_id == '130': return UniChain(**kwargs)\n",
    "    elif chain_id == '1135': return LiskChain(**kwargs)\n",
    "    else: raise ValueError(f\"Unsupported chain ID: {chain_id}\")\n",
    "\n",
    "def get_async_chain(chain_id: str, **kwargs) -> AsyncChain:\n",
    "    if chain_id == '10': return AsyncOPChain(**kwargs)\n",
    "    elif chain_id == '8453': return AsyncBaseChain(**kwargs)\n",
    "    elif chain_id == '130': return AsyncUniChain(**kwargs)\n",
    "    elif chain_id == '1135': return AsyncLiskChain(**kwargs)\n",
    "    else: raise ValueError(f\"Unsupported chain ID: {chain_id}\")\n",
    "\n",
    "def get_chain_from_token(t: Token, **kwargs) -> Chain: return get_chain(t.chain_id, **kwargs)\n",
    "def get_async_chain_from_token(t: Token, **kwargs) -> AsyncChain: return get_async_chain(t.chain_id, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simnet versions of chains\n",
    "\n",
    "Simnet URIs:\n",
    "\n",
    "- OP: http://127.0.0.1:4444\n",
    "- Base: http://127.0.0.1:4445\n",
    "- Lisk: http://127.0.0.1:4446\n",
    "\n",
    "This assumes the following setup:\n",
    "\n",
    "```\n",
    "supersim fork  --l2.host=0.0.0.0 --l2.starting.port=4444 --chains=op,base,lisk\n",
    "```\n",
    "\n",
    "For local dev, use:\n",
    "\n",
    "```\n",
    "python ./supersim.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class AsyncOPChainSimnet(AsyncOPChain):\n",
    "    def __init__(self,  **kwargs): super().__init__(rpc_uri=\"http://127.0.0.1:4444\", **kwargs)\n",
    "\n",
    "class AsyncBaseChainSimnet(AsyncBaseChain):\n",
    "    def __init__(self,  **kwargs): super().__init__(rpc_uri=\"http://127.0.0.1:4445\", **kwargs)\n",
    "\n",
    "class OPChainSimnet(OPChain):\n",
    "    def __init__(self,  **kwargs): super().__init__(rpc_uri=\"http://127.0.0.1:4444\", **kwargs)\n",
    "\n",
    "class BaseChainSimnet(BaseChain):\n",
    "    def __init__(self,  **kwargs): super().__init__(rpc_uri=\"http://127.0.0.1:4445\", **kwargs)\n",
    "\n",
    "class LiskChainSimnet(LiskChain):\n",
    "    def __init__(self,  **kwargs): super().__init__(rpc_uri=\"http://127.0.0.1:4446\", **kwargs)\n",
    "\n",
    "class AsyncLiskChainSimnet(AsyncLiskChain):\n",
    "    def __init__(self,  **kwargs): super().__init__(rpc_uri=\"http://127.0.0.1:4445\", **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "Run tests using mainnets for reads and supersim for writes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure supersim is running. Make sure PK is set for writes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "==:\n61\n0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[32m      6\u001b[39m load_dotenv()\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mrequire_supersim\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m test_ne(os.getenv(\u001b[33m\"\u001b[39m\u001b[33mSUGAR_PK\u001b[39m\u001b[33m\"\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/sugar-sdk/sugar/helpers.py:265\u001b[39m, in \u001b[36mrequire_supersim\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    263\u001b[39m     result = sock.connect_ex((\u001b[33m'\u001b[39m\u001b[33m127.0.0.1\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m4444\u001b[39m))\n\u001b[32m    264\u001b[39m     \u001b[38;5;66;03m# are you running supersim?\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m     \u001b[43mtest_eq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m socket.error \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    267\u001b[39m     test_eq(err, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/sugar-sdk/env/lib/python3.11/site-packages/fastcore/test.py:39\u001b[39m, in \u001b[36mtest_eq\u001b[39m\u001b[34m(a, b)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtest_eq\u001b[39m(a,b):\n\u001b[32m     38\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m`test` that `a==b`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43mequals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m==\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/sugar-sdk/env/lib/python3.11/site-packages/fastcore/test.py:29\u001b[39m, in \u001b[36mtest\u001b[39m\u001b[34m(a, b, cmp, cname)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[33m\"\u001b[39m\u001b[33m`assert` that `cmp(a,b)`; display inputs and `cname or cmp.__name__` if it fails\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cname \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: cname=cmp.\u001b[34m__name__\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m cmp(a,b),\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00ma\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mb\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAssertionError\u001b[39m: ==:\n61\n0"
     ]
    }
   ],
   "source": [
    "from sugar.helpers import require_supersim\n",
    "from fastcore.test import test_ne, test_eq, test_close\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "require_supersim()\n",
    "test_ne(os.getenv(\"SUGAR_PK\"), None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check simnet URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async with AsyncOPChainSimnet() as op:\n",
    "    assert \"127.0.0.1\" in op.settings.rpc_uri\n",
    "async with AsyncBaseChainSimnet() as base:\n",
    "    assert \"127.0.0.1\" in base.settings.rpc_uri\n",
    "async with AsyncLiskChainSimnet() as lisk:\n",
    "    assert \"127.0.0.1\" in lisk.settings.rpc_uri\n",
    "with OPChainSimnet() as op:\n",
    "    assert \"127.0.0.1\" in op.settings.rpc_uri\n",
    "with BaseChainSimnet() as base:\n",
    "    assert \"127.0.0.1\" in base.settings.rpc_uri\n",
    "with LiskChainSimnet() as lisk:\n",
    "    assert \"127.0.0.1\" in lisk.settings.rpc_uri\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check chain IDs and names. Test helpers: get_chain and get_async_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with BaseChain() as base: test_eq(base.chain_id, \"8453\"), test_eq(base.name, \"Base\")\n",
    "async with AsyncBaseChain() as base: test_eq(base.chain_id, \"8453\"), test_eq(base.name, \"Base\")\n",
    "\n",
    "async with AsyncOPChain() as op:test_eq(op.chain_id, \"10\"), test_eq(op.name, \"OP\")\n",
    "with OPChain() as op: test_eq(op.chain_id, \"10\"), test_eq(op.name, \"OP\")\n",
    "\n",
    "async with AsyncUniChain() as uni: test_eq(uni.chain_id, \"130\"), test_eq(uni.name, \"Uni\")\n",
    "with UniChain() as uni: test_eq(uni.chain_id, \"130\"), test_eq(uni.name, \"Uni\")\n",
    "\n",
    "async with AsyncLiskChain() as lisk: test_eq(lisk.chain_id, \"1135\"), test_eq(lisk.name, \"Lisk\")\n",
    "with LiskChain() as lisk: test_eq(lisk.chain_id, \"1135\"), test_eq(lisk.name, \"Lisk\")\n",
    "\n",
    "assert get_chain(\"10\")\n",
    "assert get_async_chain(\"10\")\n",
    "assert get_chain(\"8453\")\n",
    "assert get_async_chain(\"8453\")\n",
    "assert get_chain(\"130\")\n",
    "assert get_async_chain(\"130\")\n",
    "assert get_chain(\"1135\")\n",
    "assert get_async_chain(\"1135\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check real chain URLs - let's make sure we are not running on public stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async with AsyncOPChain() as op:\n",
    "    assert op.settings.rpc_uri != \"https://mainnet.base.org\"\n",
    "\n",
    "async with AsyncBaseChain() as base:\n",
    "    assert base.settings.rpc_uri != \"https://optimism-mainnet.wallet.coinbase.com\"\n",
    "\n",
    "async with AsyncUniChain() as uni:\n",
    "    assert uni.settings.rpc_uri != \"https://unichain.drpc.org\"\n",
    "\n",
    "async with AsyncLiskChain() as lisk:\n",
    "    assert lisk.settings.rpc_uri != \"https://lisk.drpc.org\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting tokens: \n",
    "\n",
    "- make sure native token is included\n",
    "- check on chain IDs and names\n",
    "- check for superswap connector tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get tokens async took 0.2998 seconds\n",
      "Get tokens sync took 0.2463 seconds\n",
      "Get tokens async on Base took 1.0324 seconds\n",
      "Get tokens async on Uni took 0.1095 seconds\n",
      "Get tokens sync on Uni took 0.1838 seconds\n"
     ]
    }
   ],
   "source": [
    "from fastcore.test import test_eq, test_ne\n",
    "\n",
    "async with AsyncOPChain() as op:\n",
    "    async with atime_it(\"Get tokens async\"): tokens = await op.get_all_tokens()\n",
    "    native_token = next(filter(lambda t: t.is_native, tokens), None)\n",
    "    test_ne(native_token, None), test_eq(native_token.symbol, \"ETH\")\n",
    "\n",
    "    for t in tokens: test_eq(t.chain_id, op.chain_id), test_eq(t.chain_name, op.name)\n",
    "\n",
    "    bridge = await op.get_bridge_token()\n",
    "    test_ne(bridge, None)\n",
    "\n",
    "with OPChain() as op_sync:\n",
    "    with time_it(\"Get tokens sync\"): tokens = op_sync.get_all_tokens()\n",
    "    native_token = next(filter(lambda t: t.is_native, tokens), None)\n",
    "    test_ne(native_token, None), test_eq(native_token.symbol, \"ETH\")\n",
    "\n",
    "    for t in tokens: test_eq(t.chain_id, op.chain_id), test_eq(t.chain_name, op.name)\n",
    "\n",
    "    bridge = op_sync.get_bridge_token()\n",
    "    test_ne(bridge, None)\n",
    "\n",
    "async with AsyncBaseChain() as base:\n",
    "    async with atime_it(\"Get tokens async on Base\"): tokens = await base.get_all_tokens()\n",
    "    native_token = next(filter(lambda t: t.is_native, tokens), None)\n",
    "    test_ne(native_token, None), test_eq(native_token.symbol, \"ETH\")\n",
    "\n",
    "    for t in tokens: test_eq(t.chain_id, base.chain_id), test_eq(t.chain_name, base.name)\n",
    "\n",
    "    # TODO: need superswap connector token\n",
    "\n",
    "async with AsyncUniChain() as uni:\n",
    "    async with atime_it(\"Get tokens async on Uni\"): tokens = await uni.get_all_tokens()\n",
    "    assert len(tokens) > 0, \"No tokens found on Uni chain\"\n",
    "\n",
    "    # TODO: figure out native token situation on Uni chain\n",
    "    native_token = next(filter(lambda t: t.is_native, tokens), None)\n",
    "    test_ne(native_token, None), test_eq(native_token.symbol, \"ETH\")\n",
    "\n",
    "    for t in tokens: test_eq(t.chain_id, uni.chain_id), test_eq(t.chain_name, uni.name)\n",
    "\n",
    "    bridge = await uni.get_bridge_token()\n",
    "    test_ne(bridge, None)\n",
    "\n",
    "with UniChain() as uni_sync:\n",
    "    with time_it(\"Get tokens sync on Uni\"): tokens = uni_sync.get_all_tokens()\n",
    "    assert len(tokens) > 0, \"No tokens found on Uni chain\"\n",
    "\n",
    "    # TODO: figure out native token situation on Uni chain\n",
    "    native_token = next(filter(lambda t: t.is_native, tokens), None)\n",
    "    test_ne(native_token, None), test_eq(native_token.symbol, \"ETH\")\n",
    "\n",
    "    for t in tokens: test_eq(t.chain_id, uni.chain_id), test_eq(t.chain_name, uni.name)\n",
    "\n",
    "    bridge = uni_sync.get_bridge_token()\n",
    "    test_ne(bridge, None)\n",
    "\n",
    "# test get_token by address\n",
    "async with AsyncOPChain() as op:\n",
    "    token = await op.get_token(op.velo.token_address)  # VELO\n",
    "    test_ne(token, None), test_eq(token.symbol, \"VELO\")\n",
    "    test_eq(token.chain_id, op.chain_id), test_eq(token.chain_name, op.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check on pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common sense checks\n",
    "\n",
    "async def test_all_chain_pools():\n",
    "    \"\"\"Test pools for all chains (both async and sync) with comprehensive validation\"\"\"\n",
    "    \n",
    "    # Chain test configuration\n",
    "    tests = [\n",
    "        {\"name\": \"Base\", \"async_cls\": AsyncBaseChain, \"sync_cls\": BaseChain, \"min_pools\": 7500},\n",
    "        {\"name\": \"OP\", \"async_cls\": AsyncOPChain, \"sync_cls\": OPChain, \"min_pools\": 1300},\n",
    "        {\"name\": \"Uni\", \"async_cls\": AsyncUniChain, \"sync_cls\": UniChain, \"min_pools\": 8},\n",
    "        {\"name\": \"Lisk\", \"async_cls\": AsyncLiskChain, \"sync_cls\": LiskChain, \"min_pools\": 20}  \n",
    "    ]\n",
    "    \n",
    "    results = {\"async\": {}, \"sync\": {}}\n",
    "    \n",
    "    # Test all chains\n",
    "    for test_config in tests:\n",
    "        name, min_pools = test_config[\"name\"], test_config[\"min_pools\"]\n",
    "        \n",
    "        # Test async version\n",
    "        async with test_config[\"async_cls\"]() as chain:\n",
    "            async with atime_it(f\"Get pools async on {name}\"):\n",
    "                async_pools = await chain.get_pools()\n",
    "            async with atime_it(f\"Get pools for swap async on {name}\"):\n",
    "                async_pools_for_swaps = await chain.get_pools(for_swaps=True)\n",
    "            \n",
    "            # Validate\n",
    "            test_eq(len(async_pools) >= min_pools, True)\n",
    "            for p in async_pools + async_pools_for_swaps:\n",
    "                test_eq(p.chain_id, chain.chain_id), test_eq(p.chain_name, chain.name)\n",
    "            \n",
    "            results[\"async\"][name] = {\"pools\": async_pools, \"pools_for_swaps\": async_pools_for_swaps}\n",
    "        \n",
    "        # Test sync version\n",
    "        with test_config[\"sync_cls\"]() as chain:\n",
    "            with time_it(f\"Get pools sync on {name}\"):\n",
    "                sync_pools = chain.get_pools()\n",
    "            with time_it(f\"Get pools for swap sync on {name}\"):\n",
    "                sync_pools_for_swaps = chain.get_pools(for_swaps=True)\n",
    "            \n",
    "            # Validate\n",
    "            test_eq(len(sync_pools) >= min_pools, True)\n",
    "            for p in sync_pools + sync_pools_for_swaps:\n",
    "                test_eq(p.chain_id, chain.chain_id), test_eq(p.chain_name, chain.name)\n",
    "            \n",
    "            results[\"sync\"][name] = {\"pools\": sync_pools, \"pools_for_swaps\": sync_pools_for_swaps}\n",
    "        \n",
    "        # Compare async vs sync counts\n",
    "        test_eq(len(results[\"sync\"][name][\"pools\"]), len(results[\"async\"][name][\"pools\"]))\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "await test_all_chain_pools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get prices async on op took 1.2233 seconds\n",
      "ETH price: $2450.4925363147167\n",
      "opxveVELO price: $0.04467762746171295\n",
      "VELO price: $0.04447440104078095\n",
      "RED price: $0.06975466912841975\n",
      "USDC price: $1.0\n",
      "sAMM-opxveVELO/VELO pool: $188.1678012055304\n",
      "vAMM-RED/VELO pool: $117111.26448623478\n",
      "vAMM-USDC/VELO pool: $255817.5745249826\n",
      "vAMM-UNLOCK/VELO pool: $266.1674162048505\n",
      "vAMM-WETH/VELO pool: $420355.8325947424\n",
      "Get prices async on base took 1.7086 seconds\n",
      "ETH price: $2437.797558410829\n",
      "tBTC price: $106143.80483396706\n",
      "USDbC price: $0.9972072624317969\n",
      "WETH price: $2437.797558410829\n",
      "T price: $0.017878392066954338\n",
      "vAMM-tBTC/USDbC pool: $91818.86984304269\n",
      "vAMM-tBTC/WETH pool: $369980.71891927667\n",
      "vAMM-T/WETH pool: $16.576799829114805\n",
      "vAMM-EXTRA/USDbC pool: $1479.7138986961909\n",
      "sAMM-DOLA/USDbC pool: $401822.61958548694\n"
     ]
    }
   ],
   "source": [
    "async with AsyncOPChain() as op:\n",
    "    async with AsyncBaseChain() as base:\n",
    "        chains = { \"op\": op, \"base\": base }\n",
    "\n",
    "        for name, chain in chains.items():\n",
    "            tokens = await chain.get_all_tokens()\n",
    "\n",
    "            async with atime_it(f\"Get prices async on {name}\"):\n",
    "                prices = await chain.get_prices(tokens)\n",
    "            pools = await chain.get_pools()    \n",
    "\n",
    "            for p in prices[:5]: print(f\"{p.token.symbol} price: ${p.price}\")\n",
    "            for p in pools[:5]: print(f\"{p.symbol} pool: ${p.tvl}\")\n",
    "\n",
    "            # getting pool by ID\n",
    "            first_pool = pools[0]\n",
    "            p = await chain.get_pool_by_address(first_pool.lp)\n",
    "\n",
    "            test_eq(first_pool.lp, p.lp)\n",
    "            test_eq(first_pool.symbol, p.symbol)\n",
    "\n",
    "            # not a pool\n",
    "            p = await chain.get_pool_by_address(first_pool.factory)\n",
    "            test_eq(p, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get prices sync on op took 2.3005 seconds\n",
      "ETH price: $2450.491537211601\n",
      "opxveVELO price: $0.044677583127635215\n",
      "VELO price: $0.044474382907890526\n",
      "RED price: $0.06975462969267072\n",
      "USDC price: $1.0\n",
      "sAMM-opxveVELO/VELO pool: $188.1676803058648\n",
      "vAMM-RED/VELO pool: $117111.22320877538\n",
      "vAMM-USDC/VELO pool: $255817.5224576856\n",
      "vAMM-UNLOCK/VELO pool: $266.16722992589894\n",
      "vAMM-WETH/VELO pool: $420355.6612809469\n",
      "Get prices sync on base took 1.7055 seconds\n",
      "ETH price: $2437.6098753855704\n",
      "FLYM price: $0.0\n",
      "cdxUSD price: $0.9974598842019261\n",
      "USDz price: $0.98764637478363\n",
      "AIXBT price: $0.12808463861072616\n",
      "CL2000-FLYM/cdxUSD pool: $0.0\n",
      "CL200-USDz/AIXBT pool: $9.87643787255889e-19\n",
      "CL2000-HMM/cdxUSD pool: $0.0\n",
      "CL50-USDz/sUSDz pool: $1273779.475425523\n",
      "CL2000-WHY/cdxUSD pool: $0.0\n"
     ]
    }
   ],
   "source": [
    "with OPChain() as op:\n",
    "    with BaseChain() as base:\n",
    "        chains = { \"op\": op, \"base\": base }\n",
    "\n",
    "        for name, chain in chains.items():\n",
    "            tokens = chain.get_all_tokens()\n",
    "    \n",
    "            with time_it(f\"Get prices sync on {name}\"):\n",
    "                prices = chain.get_prices(tokens)\n",
    "            pools = chain.get_pools()    \n",
    "\n",
    "            for p in prices[:5]: print(f\"{p.token.symbol} price: ${p.price}\")\n",
    "            for p in pools[:5]: print(f\"{p.symbol} pool: ${p.tvl}\")\n",
    "\n",
    "            # getting pool by ID\n",
    "            first_pool = pools[0]\n",
    "            p = chain.get_pool_by_address(first_pool.lp)\n",
    "\n",
    "            test_eq(first_pool.lp, p.lp)\n",
    "            test_eq(first_pool.symbol, p.symbol)\n",
    "\n",
    "            # not a pool\n",
    "            p = chain.get_pool_by_address(first_pool.factory)\n",
    "            test_eq(p, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pool epochs: fees and rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get latest pool epochs async took 3.6631 seconds\n",
      "Get latest pool epochs sync took 4.1567 seconds\n",
      "vAMM-RED/VELO\n",
      "Epoch date: 2025-06-26 01:00:00\n",
      "Fees: 50.44740813236096 RED 194.94826566347115 VELO 12.189138719982864\n",
      "Incentives: 2000.0 RED 139.50919315553455\n"
     ]
    }
   ],
   "source": [
    "async with AsyncOPChain() as chain:\n",
    "    with OPChain() as sync_chain:\n",
    "        async with atime_it(\"Get latest pool epochs async\"):\n",
    "            async_epochs = await chain.get_latest_pool_epochs()\n",
    "        \n",
    "        with time_it(\"Get latest pool epochs sync\"):\n",
    "            epochs = sync_chain.get_latest_pool_epochs()\n",
    "        test_eq(len(async_epochs), len(epochs))\n",
    "        \n",
    "        ep = async_epochs[0]\n",
    "        ep1 = (await chain.get_pool_epochs(ep.lp, 0, 1))[0]\n",
    "        ep2 = sync_chain.get_pool_epochs(ep.lp, 0, 1)[0]\n",
    "\n",
    "        test_eq(ep.lp, ep1.lp)\n",
    "        test_eq(ep.ts, ep1.ts)\n",
    "        test_eq(ep2.lp, ep.lp)\n",
    "        test_eq(ep2.ts, ep.ts)\n",
    "\n",
    "        print(f\"{ep.pool.symbol}\")\n",
    "        print(f\"Epoch date: {ep.epoch_date}\")\n",
    "        print(f\"Fees: {' '.join([f'{fee.amount} {fee.token.symbol}' for fee in ep.fees])} {ep.total_fees}\")\n",
    "        print(f\"Incentives: {' '.join([f'{incentive.amount} {incentive.token.symbol}' for incentive in ep.incentives])} {ep.total_incentives}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure sync VS async quote return consistent results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get async quote took 6.3299 seconds\n",
      "Get sync quote took 6.6658 seconds\n"
     ]
    }
   ],
   "source": [
    " # velo -> usdc\n",
    "\n",
    "async with AsyncOPChain() as op:\n",
    "    async with atime_it(\"Get async quote\"):\n",
    "        q1 = await op.get_quote(from_token=op.velo, to_token=op.usdc, amount=op.velo.parse_units(10))\n",
    "    amount_out1 = op.usdc.to_float(q1.amount_out)\n",
    "\n",
    "\n",
    "with OPChain() as op:\n",
    "    with time_it(\"Get sync quote\"):\n",
    "        q2 = op.get_quote(from_token=op.velo, to_token=op.usdc, amount=op.velo.parse_units(10))\n",
    "    \n",
    "    amount_out2 = op.usdc.to_float(q2.amount_out)\n",
    "\n",
    "test_close(amount_out1, amount_out2, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic deposit on OP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# async with AsyncOPChain() as chain:\n",
    "#     pools = await chain.get_pools()\n",
    "#     pools = list(filter(lambda x: x.token0 and x.token0.token_address == chain.usdc and x.token1.token_address == chain.velo, pools))\n",
    "#     async with AsyncOPChainSimnet() as supersim:\n",
    "#         print(f\"supersim is {supersim}\")\n",
    "#         # 0.02 USDC \n",
    "#         await supersim.deposit(Deposit(pools[0], 0.02))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Native -> non Native on OP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WIP\n",
    "# async with OPChain() as op:\n",
    "#     pools = await op.get_pools()\n",
    "#     # find WETH/Velo pool\n",
    "#     weth_velo_pool = next(filter(lambda p: p.token0.token_address == op.settings.wrapped_native_token_addr and p.token1.token_address == OPChain.velo, pools), None)\n",
    "#     test_ne(weth_velo_pool, None)\n",
    "#     async with OPChainSimnet() as supersim:\n",
    "#         await supersim.deposit(Deposit(weth_velo_pool, 0.0001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic deposit on Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# async with AsyncBaseChain() as chain:\n",
    "#     pools = await chain.get_pools()\n",
    "#     pools = list(filter(lambda x: x.token0 and x.token0.token_address == chain.usdc and x.token1.token_address == chain.aero, pools))\n",
    "#     async with AsyncBaseChainSimnet() as supersim:\n",
    "#         # 0.02 USDC \n",
    "#         await supersim.deposit(Deposit(pools[0], 0.01), slippage=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CL on OP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIP\n",
    "# async with OPChain() as chain:\n",
    "#     pools = await chain.get_pools()\n",
    "#     # CL200-USDC/VELO\n",
    "#     cl_usdc_velo = next(filter(lambda x: x.token0 and x.token0.token_address == chain.usdc and x.token1.token_address == chain.velo and x.is_cl, pools), None)\n",
    "#     test_ne(cl_usdc_velo, None)\n",
    "#     async with OPChainSimnet() as supersim:\n",
    "#         await supersim.deposit(Deposit(cl_usdc_velo, 0.02))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
